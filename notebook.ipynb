{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook presents the core implementations of our method and uses that to train ensembles of 2 or 3 ResNet-18 models on CIFAR-10. It computes the transferability rates for ```Orig```, ```C=1.0```, and ```LOTOS C=1.0 mal=0.8``` using white-box attack as explained in our paper and generates similar plots to the ones we have in the experiments section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "from advertorch.attacks.utils import attack_whole_dataset\n",
    "from advertorch.attacks import LinfPGDAttack\n",
    "\n",
    "from models.resnet import ResNet18\n",
    "from models.resnet_orig import ResNet18_orig\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from utils.Empirical.utils_ensemble import AverageMeter, requires_grad_\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting a set of parameters that are the default ones for our experiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = 50\n",
    "conv_freq = 1\n",
    "effective_epoch = 0\n",
    "conv_only = True\n",
    "conv_1st_only = False\n",
    "num_models = 2\n",
    "opt_iter = 1\n",
    "clip_steps = 100\n",
    "bn_flag = False\n",
    "epochs = 121\n",
    "in_chan = 3\n",
    "num_classes = 10\n",
    "bottom_clip = 0.8 # mal value\n",
    "cat_bottom_clip = 0.8 # mal value for the concatenation when batchnorm is used\n",
    "conv_factor = 0.05\n",
    "cat_factor = 0.05\n",
    "adv_eps = 0.04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function to extract and compute the average of transferability rate, roubstness, and accuracy for the models in the ensemble for each epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_trans(sub_df, model_count=3):\n",
    "    ### computing the average of the transferability rates from pairs of models\n",
    "    if model_count == 3:\n",
    "        trans_mat = sub_df[['t0', 't1', 't2']].values\n",
    "    elif model_count == 2:\n",
    "        trans_mat = sub_df[['t0', 't1']].values\n",
    "    acc_avg = sub_df['acc'].mean()\n",
    "\n",
    "    # compute the sum of off-diagonal values of trans_mat:\n",
    "    off_diagonal_sum = np.sum(trans_mat) - np.trace(trans_mat)\n",
    "    if model_count == 3:\n",
    "        trans_rate = off_diagonal_sum / 6.\n",
    "    elif model_count == 2:\n",
    "        trans_rate = off_diagonal_sum / 2.\n",
    "\n",
    "    if model_count == 3:\n",
    "        robustness = 1. - np.trace(trans_mat) / 3.\n",
    "    elif model_count == 2:\n",
    "        robustness = 1. - np.trace(trans_mat) / 2.\n",
    "\n",
    "    return trans_rate, robustness, acc_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(df, num_models):\n",
    "    trans_df_1_group = df.groupby('epoch')\n",
    "    results = []\n",
    "    for idx, group in trans_df_1_group:\n",
    "        group = group[:num_models]\n",
    "        trans_rate, robustness, acc_avg = compute_trans(group, num_models)\n",
    "        results.append([int(idx),trans_rate, robustness, acc_avg])\n",
    "    res_df = pd.DataFrame(results, columns=['epoch', 'trans', 'robust', 'acc'])\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function to use the white-box attacks (see our paper for details) to compute the transferability rate of adversarial examples between each ordered pair of models in the ensemble:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaltrans_correct(loader, models, criterion, epoch):\n",
    "    ### performing white-box attack to compute the transferability rates\n",
    "    for i in range(len(models)):\n",
    "        models[i].eval()\n",
    "\n",
    "    adv = []\n",
    "    advsamples_lst = []\n",
    "    pred_lst = []\n",
    "    advpred_lst = []   \n",
    "    label = None\n",
    "    for i in range(len(models)):\n",
    "        curmodel = models[i]\n",
    "        adversary = LinfPGDAttack(\n",
    "            curmodel, loss_fn=criterion, eps=adv_eps,\n",
    "            nb_iter=50, eps_iter=adv_eps / 10, rand_init=True, clip_min=0., clip_max=1.,\n",
    "            targeted=False)\n",
    "\n",
    "        adv.append(adversary)\n",
    "        advsamples, label, pred, advpred = attack_whole_dataset(adversary, loader, device=device)\n",
    "        advsamples_lst.append(advsamples)\n",
    "        pred_lst.append(pred)\n",
    "        advpred_lst.append(advpred)\n",
    "\n",
    "    trans_list = []\n",
    "    accs = np.zeros(num_models)\n",
    "    trans = np.zeros((num_models, num_models))\n",
    "    for i in range(len(models)):\n",
    "        _, label, pred, advpred = advsamples_lst[i], label, pred_lst[i], advpred_lst[i]\n",
    "\n",
    "        for j in range(len(models)):\n",
    "            if j==i:\n",
    "                if trans[i][j] > 0.00000001:\n",
    "                    continue\n",
    "                y = label[label == pred]\n",
    "                accs[i] = y.size(0) / label.size(0)\n",
    "                y_wrong = label[(label == pred) & (advpred != label)]\n",
    "                trans[i][j] = y_wrong.size(0) / len(y)\n",
    "\n",
    "            else:\n",
    "                inputc = _[(label == pred) & (advpred != label) & (label==pred_lst[j])]\n",
    "                print('model: ', i, inputc.size(0), ' out of ', _.size(0))\n",
    "                y = label[(label == pred) & (advpred != label) & (label==pred_lst[j])]\n",
    "            \n",
    "                with torch.no_grad():\n",
    "                    for r in range((inputc.size(0) - 1) // 100 + 1):\n",
    "                        inputc_sub = inputc[r * 200: min((r + 1) * 200, inputc.size(0))]\n",
    "                        if len(inputc_sub) == 0:\n",
    "                            break\n",
    "                        y_sub = y[r * 200: min((r + 1) * 200, inputc.size(0))]\n",
    "                        __ = adv[j].predict(inputc_sub)\n",
    "                        output = (__).max(1, keepdim=False)[1]\n",
    "                        trans[i][j] += (output != y_sub).sum().item()\n",
    "                    trans[i][j] /= len(y)\n",
    "\n",
    "            print(i, j, trans[i][j])\n",
    "\n",
    "        new_list = [epoch]\n",
    "        for k in range(num_models):\n",
    "            new_list.append(trans[i,k])\n",
    "        new_list.append(accs[i])\n",
    "        new_tup = tuple(new_list)\n",
    "        trans_list.append(new_tup)\n",
    "\n",
    "    return trans_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function used for training each each epoch. By setting the ```lotos_flag``` to true, it uses LOTOS for training, otherwise it uses regular training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Naive_Trainer_ortho(loader: DataLoader, models, criterion, optimizer, epoch: int, device: torch.device, lotos_flag=False, \n",
    "                        catclip=False, no_effect_epochs=0, batch_counter=0, mal_freq=100, conv_freq=50, layer_1_only=False, \n",
    "                        conv_1st_only=False, lsv_list_dict={}, lsv_list_dict_conv={}, conv_only=False, conv_factor=0.05, cat_factor=0.05):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    reg_losses = AverageMeter()\n",
    "    ortho_losses = AverageMeter()\n",
    "\n",
    "    end = time.time()\n",
    "    ortho_total = 0.\n",
    "\n",
    "    ortho_flag = lotos_flag\n",
    "    decrement = 0.01\n",
    "    weights = torch.from_numpy(np.array([1 - decrement*i for i in range(100)])).to(device)\n",
    "\n",
    "    print_freq = max(1000, 10*conv_freq)\n",
    "    if len(lsv_list_dict) == 0:\n",
    "        print('initiating lsv list dict')\n",
    "        for j in range(num_models):\n",
    "            lsv_list_dict[j] = None\n",
    "            lsv_list_dict_conv[j] = None\n",
    "\n",
    "    for i in range(num_models):\n",
    "        models[i].train()\n",
    "        requires_grad_(models[i], True)\n",
    "\n",
    "    cat_counter_info = 0\n",
    "    conv_counter_info = 0\n",
    "    for i, (inputs, targets) in enumerate(loader):\n",
    "        data_time.update(time.time() - end)\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        batch_size = inputs.size(0)\n",
    "        loss_std = 0\n",
    "        ortho_loss = 0\n",
    "        ortho_loss_conv = 0\n",
    "\n",
    "        for j in range(num_models):\n",
    "            logits = models[j](inputs)\n",
    "            loss = criterion(logits, targets)\n",
    "            loss_std += loss\n",
    "\n",
    "            if not ortho_flag:\n",
    "                continue\n",
    "            if i == len(loader)-1:\n",
    "                continue\n",
    "\n",
    "            VT_list = []\n",
    "            VT_list_conv = []\n",
    "            idx = 0\n",
    "\n",
    "            conv_count = 0\n",
    "            cat_counter_info = 0\n",
    "            conv_counter_info = 0\n",
    "\n",
    "            for (m_name, m) in models[j].named_modules():\n",
    "                condition = isinstance(m, (torch.nn.Conv2d))\n",
    "                condition_conv = isinstance(m, (torch.nn.Conv2d))\n",
    "                if not condition_conv and conv_only:\n",
    "                    continue\n",
    "                if catclip:\n",
    "                    condition = not conv_only and not isinstance(m, (torch.nn.Conv2d)) and (not isinstance(m, torch.nn.BatchNorm2d) and not isinstance(m, torch.nn.Linear))\n",
    "\n",
    "                if not condition_conv and epoch < no_effect_epochs:\n",
    "                    conv_factor = 0.0\n",
    "                    cat_factor = 0.0\n",
    "\n",
    "                if condition or condition_conv:\n",
    "                    attrs = vars(m)\n",
    "                    for item in attrs.items():\n",
    "                        if item[0] == '_buffers' and 'weight_VT' in item[1]:\n",
    "                            VT = item[1]['weight_VT']\n",
    "                            if batch_counter != 0:\n",
    "                                first_flag = True\n",
    "                                for k in range(num_models):\n",
    "                                    if k == j:\n",
    "                                        if condition_conv:\n",
    "                                            if batch_counter % print_freq != 0:\n",
    "                                                continue\n",
    "                                            prev_VT = lsv_list_dict_conv[k]\n",
    "                                            sing_vector = prev_VT[conv_count]\n",
    "                                        else:\n",
    "                                            if batch_counter % mal_freq != 0:\n",
    "                                                continue\n",
    "                                            prev_VT = lsv_list_dict[k]\n",
    "                                            sing_vector = prev_VT[idx]\n",
    "\n",
    "                                        sing_vector = torch.nn.parameter.Parameter(data=sing_vector, requires_grad=False)\n",
    "                                        op_shape = [i for i in range(1, len(sing_vector.shape))]\n",
    "                                        lsv_check = torch.sqrt(torch.sum(m(sing_vector) **2, axis=op_shape))/torch.sqrt(torch.sum(sing_vector **2, axis=op_shape)) \n",
    "                                        lsv_check_noBias = torch.sqrt(torch.sum( (m(sing_vector) - m(torch.zeros_like(sing_vector) ) )**2, axis=op_shape))/torch.sqrt(torch.sum(sing_vector **2, axis=op_shape)) \n",
    "                                        continue\n",
    "\n",
    "                                    if condition_conv:\n",
    "                                        prev_VT_list = lsv_list_dict_conv[k]\n",
    "                                    else:\n",
    "                                        prev_VT_list = lsv_list_dict[k]\n",
    "\n",
    "                                    if not condition_conv and layer_1_only and idx > 0:\n",
    "                                        continue\n",
    "                                    if condition_conv and conv_1st_only and conv_count > 0:\n",
    "                                        continue\n",
    "\n",
    "                                    if condition_conv:\n",
    "                                        bad_vector = prev_VT_list[conv_count]\n",
    "                                    else:\n",
    "                                        bad_vector = prev_VT_list[idx]\n",
    "\n",
    "                                    if batch_counter % mal_freq != 0 and not condition_conv:\n",
    "                                        continue\n",
    "                                    if batch_counter % conv_freq != 0 and condition_conv:\n",
    "                                        continue\n",
    "\n",
    "                                    bad_vector = torch.nn.parameter.Parameter(data=bad_vector, requires_grad=False)\n",
    "                                    op_shape = [i for i in range(1, len(bad_vector.shape))]\n",
    "                                    bad_vec_length = torch.sqrt(torch.sum((m(bad_vector) - m(torch.zeros_like(bad_vector)) )**2, axis=op_shape))/torch.sqrt(torch.sum(bad_vector **2, axis=op_shape)) ##### fix this shit for multiple vectors!                       \n",
    "\n",
    "                                    if condition_conv:\n",
    "                                        bad_vec_length_thresh = torch.nn.functional.relu(bad_vec_length-bottom_clip)\n",
    "                                    else:\n",
    "                                        bad_vec_length_thresh = torch.nn.functional.relu(bad_vec_length-cat_bottom_clip)\n",
    "\n",
    "                                    bad_vec_length_weighted = torch.sum(torch.mul(bad_vec_length_thresh, weights[:len(bad_vec_length_thresh)]))/torch.sum(weights[:len(bad_vec_length_thresh)])\n",
    "\n",
    "                                    if condition_conv:\n",
    "                                        ortho_loss_conv += conv_factor * bad_vec_length_weighted\n",
    "                                        conv_counter_info += 1\n",
    "                                    if not condition_conv:\n",
    "                                        ortho_loss += cat_factor * bad_vec_length_weighted\n",
    "                                        cat_counter_info += 1\n",
    "\n",
    "                            if condition_conv:\n",
    "                                VT_list_conv.append(VT.detach())\n",
    "                                conv_count += 1\n",
    "                            else:\n",
    "                                VT_list.append(VT.detach())\n",
    "                                idx += 1\n",
    "\n",
    "            lsv_list_dict_conv[j] = VT_list_conv\n",
    "            if not conv_only:\n",
    "                lsv_list_dict[j] = VT_list\n",
    "\n",
    "        reg_losses.update(loss_std.item(), batch_size)\n",
    "        loss = loss_std\n",
    "\n",
    "        if ortho_flag:\n",
    "            pair_count = num_models * (num_models - 1) / 2\n",
    "            conv_counter_info = conv_counter_info // (num_models-1)\n",
    "            cat_counter_info = cat_counter_info // (num_models-1)\n",
    "            \n",
    "            conv_normalizer = conv_counter_info*pair_count\n",
    "            cat_normalizer = cat_counter_info*pair_count\n",
    "\n",
    "            conv_normalizer = 1.\n",
    "            cat_normalizer = 1.\n",
    "\n",
    "            if ortho_loss_conv > 0 and (batch_counter % 200 != 199) and batch_counter > 0 and conv_counter_info > 0 and (batch_counter % conv_freq) == 0:\n",
    "                loss += ortho_loss_conv / conv_normalizer #/ (conv_counter_info*pair_count)\n",
    "                ortho_total += ortho_loss_conv.item() / conv_normalizer #/ (conv_counter_info*pair_count)\n",
    "                if batch_counter % print_freq == 0:\n",
    "                    print('pairs', pair_count,  'conv', conv_counter_info,  'ortho loss conv: ', ortho_loss_conv.item()/ conv_normalizer )\n",
    "\n",
    "            # if batch_counter % 200 != 199 and not conv_only and batch_counter > 0 and cat_counter_info > 0 and (batch_counter % mal_freq) == 50:\n",
    "            if not conv_only and batch_counter > 0 and cat_counter_info > 0 and (batch_counter % mal_freq) == 50:\n",
    "                loss += ortho_loss / cat_normalizer #/ (cat_counter_info*pair_count)\n",
    "                ortho_total += ortho_loss.item() / cat_normalizer #/ (cat_counter_info*pair_count)\n",
    "                if batch_counter % mal_freq == 0:\n",
    "                    print('pairs', pair_count, 'cat', cat_counter_info, 'ortho loss cat: ', ortho_loss.item() / cat_normalizer)\n",
    "\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        batch_counter += 1\n",
    "\n",
    "    print('Epoch: ', epoch, 'Loss: ', losses.avg, 'Loss_std: ', reg_losses.avg, 'Ortho_loss: ', ortho_losses.avg, 'ortho total:', ortho_total)\n",
    "\n",
    "    return losses.avg, batch_counter, lsv_list_dict, lsv_list_dict_conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading CIFAR-10 dataset and preparing data loaders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "### Reading CIFAR10:\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10( root='./data', train=True, download=True, transform=transform_train)\n",
    "train_loader = torch.utils.data.DataLoader( trainset, batch_size=128, shuffle=True, num_workers=1)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10( root='./data', train=False, download=True, transform=transform_test)\n",
    "test_loader = torch.utils.data.DataLoader( testset, batch_size=128, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to perform the training on ensembles. For ```Orig``` ensembles, both ```clip_flag``` and ```lotos_flag``` should be set to False. For ```C=1```, the ```clip_flag``` should be set the True. For ```LOTOS```, both flags should be set to True:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ensemble(num_models, clip_flag=False, lotos_flag=False, seed_val=0):\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    random.seed(seed_val)\n",
    "\n",
    "    model = []\n",
    "    for i in range(num_models):\n",
    "        if clip_flag:\n",
    "            submodel = ResNet18(in_chan=in_chan, num_classes=num_classes, device=device, clip_flag=True, bn=False, clip_steps=clip_steps, writer=None)\n",
    "        else:\n",
    "            submodel = ResNet18_orig(in_chan=in_chan, num_classes=num_classes, bn=False, device=device)\n",
    "        submodel = nn.DataParallel(submodel)\n",
    "        model.append(submodel)\n",
    "    print(\"Model loaded\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "    param = list(model[0].parameters())\n",
    "    for i in range(1, num_models):\n",
    "        param.extend(list(model[i].parameters()))\n",
    "\n",
    "    optimizer = optim.SGD(param, lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=40, gamma=0.1)\n",
    "\n",
    "    trans_list = []\n",
    "    batch_counter = 0\n",
    "    lsv_list_dict = {}\n",
    "    lsv_list_dict_conv = {}\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        train_loss, batch_counter, lsv_list_dict, lsv_list_dict_conv = Naive_Trainer_ortho(train_loader, model, criterion, optimizer, \n",
    "                                                                                           epoch, device, lotos_flag=lotos_flag, catclip=False, no_effect_epochs=effective_epoch, \n",
    "                                                                                           batch_counter=batch_counter, mal_freq=freq, conv_freq=conv_freq, layer_1_only=False, \n",
    "                                                                                           conv_1st_only=conv_1st_only, lsv_list_dict=lsv_list_dict, lsv_list_dict_conv=lsv_list_dict_conv, \n",
    "                                                                                           conv_factor=conv_factor, cat_factor=cat_factor,\n",
    "                                                                                           conv_only=conv_only)\n",
    "        print('time: ', time.time() - start)\n",
    "\n",
    "        if epoch % 20 == 0 and epoch >= 60: \n",
    "            trans_list_new = evaltrans_correct(test_loader, model, criterion, epoch)\n",
    "            trans_list += trans_list_new\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    col_names = ['epoch']\n",
    "    for k in range(num_models):\n",
    "        col_names.append('t' + str(k))\n",
    "    col_names.append('acc')\n",
    "\n",
    "    df = pd.DataFrame(trans_list, columns=col_names) \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now running the training methods for 3 cases: ```Orig```, ```C=1.0```, and ```LOTOS C=1.0 mal=0.8```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n",
      "initiating lsv list dict\n",
      "Epoch:  0 Loss:  4.1711517015075685 Loss_std:  4.1711517015075685 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  21.810686111450195\n",
      "Epoch:  1 Loss:  3.5729671159362795 Loss_std:  3.5729671159362795 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  22.282235860824585\n",
      "Epoch:  2 Loss:  3.1105881300354006 Loss_std:  3.1105881300354006 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  22.268751621246338\n",
      "Epoch:  3 Loss:  2.7403625202941893 Loss_std:  2.7403625202941893 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  25.719451189041138\n",
      "Epoch:  4 Loss:  2.454787545890808 Loss_std:  2.454787545890808 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  25.305118560791016\n",
      "Epoch:  5 Loss:  2.2181022617340087 Loss_std:  2.2181022617340087 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  27.440547466278076\n",
      "Epoch:  6 Loss:  2.0530935596466064 Loss_std:  2.0530935596466064 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  22.71924090385437\n",
      "Epoch:  7 Loss:  1.8787254196929932 Loss_std:  1.8787254196929932 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  22.919981241226196\n",
      "Epoch:  8 Loss:  1.713153374671936 Loss_std:  1.713153374671936 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  25.52657461166382\n",
      "Epoch:  9 Loss:  1.596831064453125 Loss_std:  1.596831064453125 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  37.05870866775513\n",
      "Epoch:  10 Loss:  1.536628985824585 Loss_std:  1.536628985824585 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  35.09264349937439\n",
      "Epoch:  11 Loss:  1.4207092354583741 Loss_std:  1.4207092354583741 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  42.373772859573364\n",
      "Epoch:  12 Loss:  1.3772593717956543 Loss_std:  1.3772593717956543 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  42.17998957633972\n",
      "Epoch:  13 Loss:  1.31828155128479 Loss_std:  1.31828155128479 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  32.01135873794556\n",
      "Epoch:  14 Loss:  1.2604671866989137 Loss_std:  1.2604671866989137 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  30.107688188552856\n",
      "Epoch:  15 Loss:  1.2284771305465698 Loss_std:  1.2284771305465698 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  30.20463991165161\n",
      "Epoch:  16 Loss:  1.2102044592666625 Loss_std:  1.2102044592666625 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  28.842214584350586\n",
      "Epoch:  17 Loss:  1.1692722925949097 Loss_std:  1.1692722925949097 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  28.99251413345337\n",
      "Epoch:  18 Loss:  1.1558163220977784 Loss_std:  1.1558163220977784 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  32.62544322013855\n",
      "Epoch:  19 Loss:  1.1283866348266602 Loss_std:  1.1283866348266602 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  34.14475464820862\n",
      "Epoch:  20 Loss:  1.0817375690460205 Loss_std:  1.0817375690460205 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  33.16689968109131\n",
      "Epoch:  21 Loss:  1.0777320573806763 Loss_std:  1.0777320573806763 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  35.84592151641846\n",
      "Epoch:  22 Loss:  1.080193015460968 Loss_std:  1.080193015460968 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  30.56979513168335\n",
      "Epoch:  23 Loss:  1.0566661000442505 Loss_std:  1.0566661000442505 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  33.31492352485657\n",
      "Epoch:  24 Loss:  1.0243777227592468 Loss_std:  1.0243777227592468 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  30.49204659461975\n",
      "Epoch:  25 Loss:  1.0126090432739259 Loss_std:  1.0126090432739259 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  27.879918813705444\n",
      "Epoch:  26 Loss:  0.9983447542953491 Loss_std:  0.9983447542953491 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  28.031169652938843\n",
      "Epoch:  27 Loss:  0.9779267587661743 Loss_std:  0.9779267587661743 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  32.07851219177246\n",
      "Epoch:  28 Loss:  0.9883397219085693 Loss_std:  0.9883397219085693 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  22.64128017425537\n",
      "Epoch:  29 Loss:  0.9594565110778809 Loss_std:  0.9594565110778809 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  30.544130086898804\n",
      "Epoch:  30 Loss:  0.9448133476638794 Loss_std:  0.9448133476638794 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  36.16532015800476\n",
      "Epoch:  31 Loss:  0.9386782200622559 Loss_std:  0.9386782200622559 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  29.557129859924316\n",
      "Epoch:  32 Loss:  0.9603356217193604 Loss_std:  0.9603356217193604 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  29.939425468444824\n",
      "Epoch:  33 Loss:  0.9411019284439087 Loss_std:  0.9411019284439087 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  31.36668348312378\n",
      "Epoch:  34 Loss:  0.9170229725265503 Loss_std:  0.9170229725265503 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  28.571826219558716\n",
      "Epoch:  35 Loss:  0.9098711701202392 Loss_std:  0.9098711701202392 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  28.958399295806885\n",
      "Epoch:  36 Loss:  0.8940671566200257 Loss_std:  0.8940671566200257 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  30.988022565841675\n",
      "Epoch:  37 Loss:  0.8983727571868897 Loss_std:  0.8983727571868897 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  26.578569173812866\n",
      "Epoch:  38 Loss:  0.9103100130462647 Loss_std:  0.9103100130462647 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  32.866868019104004\n",
      "Epoch:  39 Loss:  0.8764338145065308 Loss_std:  0.8764338145065308 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  28.64779806137085\n",
      "Epoch:  40 Loss:  0.5137571152114868 Loss_std:  0.5137571152114868 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  31.023930549621582\n",
      "Epoch:  41 Loss:  0.42558301502227786 Loss_std:  0.42558301502227786 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  26.891916751861572\n",
      "Epoch:  42 Loss:  0.3916344404888153 Loss_std:  0.3916344404888153 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  26.463758945465088\n",
      "Epoch:  43 Loss:  0.3693424200820923 Loss_std:  0.3693424200820923 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  26.817962646484375\n",
      "Epoch:  44 Loss:  0.3477307504367828 Loss_std:  0.3477307504367828 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  29.825650215148926\n",
      "Epoch:  45 Loss:  0.3313375350475311 Loss_std:  0.3313375350475311 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  26.604212045669556\n",
      "Epoch:  46 Loss:  0.3155663152217865 Loss_std:  0.3155663152217865 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  27.924164295196533\n",
      "Epoch:  47 Loss:  0.30161815448760987 Loss_std:  0.30161815448760987 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  27.701613426208496\n",
      "Epoch:  48 Loss:  0.28949866534233093 Loss_std:  0.28949866534233093 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  25.40120244026184\n",
      "Epoch:  49 Loss:  0.2822339927196503 Loss_std:  0.2822339927196503 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  24.34756588935852\n",
      "Epoch:  50 Loss:  0.2712318474006653 Loss_std:  0.2712318474006653 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  27.759372234344482\n",
      "Epoch:  51 Loss:  0.26409802804946897 Loss_std:  0.26409802804946897 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  30.267013549804688\n",
      "Epoch:  52 Loss:  0.2558042220544815 Loss_std:  0.2558042220544815 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  25.14573335647583\n",
      "Epoch:  53 Loss:  0.25108323903560636 Loss_std:  0.25108323903560636 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  26.630608558654785\n",
      "Epoch:  54 Loss:  0.24374232157707215 Loss_std:  0.24374232157707215 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  24.12222409248352\n",
      "Epoch:  55 Loss:  0.23336834287643432 Loss_std:  0.23336834287643432 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  30.104729890823364\n",
      "Epoch:  56 Loss:  0.22922274091720582 Loss_std:  0.22922274091720582 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  27.17039680480957\n",
      "Epoch:  57 Loss:  0.2271861622619629 Loss_std:  0.2271861622619629 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  21.999751567840576\n",
      "Epoch:  58 Loss:  0.22410717757225038 Loss_std:  0.22410717757225038 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  29.818440675735474\n",
      "Epoch:  59 Loss:  0.21709283555984496 Loss_std:  0.21709283555984496 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  31.382505178451538\n",
      "Epoch:  60 Loss:  0.21118649559020997 Loss_std:  0.21118649559020997 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  25.425453901290894\n",
      "0 0 0.8247388675096207\n",
      "model:  0 7159  out of  10000\n",
      "0 1 0.8216231317223076\n",
      "model:  1 7172  out of  10000\n",
      "1 0 0.8238984941438929\n",
      "1 1 0.8238566818738178\n",
      "Epoch:  61 Loss:  0.2090276715183258 Loss_std:  0.2090276715183258 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  25.68928837776184\n",
      "Epoch:  62 Loss:  0.2100426050567627 Loss_std:  0.2100426050567627 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  26.346187114715576\n",
      "Epoch:  63 Loss:  0.2008254777908325 Loss_std:  0.2008254777908325 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  26.731767416000366\n",
      "Epoch:  64 Loss:  0.1981697139453888 Loss_std:  0.1981697139453888 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  28.77117133140564\n",
      "Epoch:  65 Loss:  0.19877874566555023 Loss_std:  0.19877874566555023 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  34.0655677318573\n",
      "Epoch:  66 Loss:  0.19255762322425843 Loss_std:  0.19255762322425843 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  55097.33865261078\n",
      "Epoch:  67 Loss:  0.18892019050598144 Loss_std:  0.18892019050598144 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  -6074.685321807861\n",
      "Epoch:  68 Loss:  0.19269548910975456 Loss_std:  0.19269548910975456 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  21.497796535491943\n",
      "Epoch:  69 Loss:  0.18696671127319336 Loss_std:  0.18696671127319336 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  21.835350275039673\n",
      "Epoch:  70 Loss:  0.1796290006828308 Loss_std:  0.1796290006828308 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  23.067395210266113\n",
      "Epoch:  71 Loss:  0.19069306191205979 Loss_std:  0.19069306191205979 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  22.018300771713257\n",
      "Epoch:  72 Loss:  0.1825718653202057 Loss_std:  0.1825718653202057 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  22.236578702926636\n",
      "Epoch:  73 Loss:  0.1819358641052246 Loss_std:  0.1819358641052246 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  21.503103017807007\n",
      "Epoch:  74 Loss:  0.1731508966112137 Loss_std:  0.1731508966112137 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  24.20436954498291\n",
      "Epoch:  75 Loss:  0.18158141944885253 Loss_std:  0.18158141944885253 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  21.65268564224243\n",
      "Epoch:  76 Loss:  0.17106274926662446 Loss_std:  0.17106274926662446 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  23.681806087493896\n",
      "Epoch:  77 Loss:  0.1657177239894867 Loss_std:  0.1657177239894867 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  23.342556715011597\n",
      "Epoch:  78 Loss:  0.17055633360862732 Loss_std:  0.17055633360862732 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  21.880879402160645\n",
      "Epoch:  79 Loss:  0.16584885560035706 Loss_std:  0.16584885560035706 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  24.419252395629883\n",
      "Epoch:  80 Loss:  0.0856990676355362 Loss_std:  0.0856990676355362 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  25.956048727035522\n",
      "0 0 0.8129957622514398\n",
      "model:  0 7217  out of  10000\n",
      "0 1 0.8359429125675488\n",
      "model:  1 7329  out of  10000\n",
      "1 0 0.8082958111611407\n",
      "1 1 0.8254747871643746\n",
      "Epoch:  81 Loss:  0.06263758563995361 Loss_std:  0.06263758563995361 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  27.385818481445312\n",
      "Epoch:  82 Loss:  0.05742373553395271 Loss_std:  0.05742373553395271 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  24.100805282592773\n",
      "Epoch:  83 Loss:  0.05134089763402939 Loss_std:  0.05134089763402939 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  26.691675186157227\n",
      "Epoch:  84 Loss:  0.04555724862098694 Loss_std:  0.04555724862098694 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  23.35581612586975\n",
      "Epoch:  85 Loss:  0.04303915990948677 Loss_std:  0.04303915990948677 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  24.816843509674072\n",
      "Epoch:  86 Loss:  0.04173991631925106 Loss_std:  0.04173991631925106 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  24.44497299194336\n",
      "Epoch:  87 Loss:  0.04166837677240372 Loss_std:  0.04166837677240372 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  24.132948398590088\n",
      "Epoch:  88 Loss:  0.03839222263753414 Loss_std:  0.03839222263753414 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  22.123252153396606\n",
      "Epoch:  89 Loss:  0.038272859064340595 Loss_std:  0.038272859064340595 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  22.16908574104309\n",
      "Epoch:  90 Loss:  0.03626458886623383 Loss_std:  0.03626458886623383 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  23.27084231376648\n",
      "Epoch:  91 Loss:  0.03522331842780113 Loss_std:  0.03522331842780113 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  26.782262086868286\n",
      "Epoch:  92 Loss:  0.034328315485045315 Loss_std:  0.034328315485045315 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  21.757078886032104\n",
      "Epoch:  93 Loss:  0.03463249055832624 Loss_std:  0.03463249055832624 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  26.53279709815979\n",
      "Epoch:  94 Loss:  0.03264179426491261 Loss_std:  0.03264179426491261 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  22.068689107894897\n",
      "Epoch:  95 Loss:  0.03093809587419033 Loss_std:  0.03093809587419033 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  26.378314971923828\n",
      "Epoch:  96 Loss:  0.029446553118228913 Loss_std:  0.029446553118228913 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  23.340741395950317\n",
      "Epoch:  97 Loss:  0.03023435645893216 Loss_std:  0.03023435645893216 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  22.075534343719482\n",
      "Epoch:  98 Loss:  0.026393858109116555 Loss_std:  0.026393858109116555 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  22.1358859539032\n",
      "Epoch:  99 Loss:  0.026919850727021695 Loss_std:  0.026919850727021695 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  27.38475465774536\n",
      "Epoch:  100 Loss:  0.02631710694730282 Loss_std:  0.02631710694730282 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  25.277522087097168\n",
      "0 0 0.8228658205879162\n",
      "model:  0 7345  out of  10000\n",
      "0 1 0.8432947583390061\n",
      "model:  1 7379  out of  10000\n",
      "1 0 0.8339883453042418\n",
      "1 1 0.8258646943658908\n",
      "Epoch:  101 Loss:  0.02516503064751625 Loss_std:  0.02516503064751625 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  23.38804864883423\n",
      "Epoch:  102 Loss:  0.025039134424328802 Loss_std:  0.025039134424328802 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  33.23002862930298\n",
      "Epoch:  103 Loss:  0.025657218738794327 Loss_std:  0.025657218738794327 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  27.1933650970459\n",
      "Epoch:  104 Loss:  0.022063161933124065 Loss_std:  0.022063161933124065 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  23.63669180870056\n",
      "Epoch:  105 Loss:  0.02348698189944029 Loss_std:  0.02348698189944029 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  33.09202456474304\n",
      "Epoch:  106 Loss:  0.023040204713195563 Loss_std:  0.023040204713195563 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  26.879454612731934\n",
      "Epoch:  107 Loss:  0.023419798173308373 Loss_std:  0.023419798173308373 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  27.17382001876831\n",
      "Epoch:  108 Loss:  0.022963323494791986 Loss_std:  0.022963323494791986 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  28.10098385810852\n",
      "Epoch:  109 Loss:  0.022083989954292775 Loss_std:  0.022083989954292775 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  27.464104652404785\n",
      "Epoch:  110 Loss:  0.023187837822437288 Loss_std:  0.023187837822437288 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  22.1287260055542\n",
      "Epoch:  111 Loss:  0.021852526867389678 Loss_std:  0.021852526867389678 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  30.12102746963501\n",
      "Epoch:  112 Loss:  0.023359857084453105 Loss_std:  0.023359857084453105 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  24.420546770095825\n",
      "Epoch:  113 Loss:  0.02163050761874765 Loss_std:  0.02163050761874765 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  28.551509141921997\n",
      "Epoch:  114 Loss:  0.021215419810712337 Loss_std:  0.021215419810712337 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  27.19622302055359\n",
      "Epoch:  115 Loss:  0.022317641642689706 Loss_std:  0.022317641642689706 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  26.42850661277771\n",
      "Epoch:  116 Loss:  0.020394389679282903 Loss_std:  0.020394389679282903 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  27.571366548538208\n",
      "Epoch:  117 Loss:  0.020108524370789527 Loss_std:  0.020108524370789527 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  26.67269515991211\n",
      "Epoch:  118 Loss:  0.01926628004014492 Loss_std:  0.01926628004014492 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  22.554290056228638\n",
      "Epoch:  119 Loss:  0.0188964107131958 Loss_std:  0.0188964107131958 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  26.243316411972046\n",
      "Epoch:  120 Loss:  0.017933554828464985 Loss_std:  0.017933554828464985 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  26.3553626537323\n",
      "0 0 0.8193045173870653\n",
      "model:  0 7335  out of  10000\n",
      "0 1 0.8406271301976823\n",
      "model:  1 7324  out of  10000\n",
      "1 0 0.8427089022392136\n",
      "1 1 0.8177869475513085\n"
     ]
    }
   ],
   "source": [
    "df_orig = train_ensemble(num_models, clip_flag=False, lotos_flag=False, seed_val=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "Model loaded\n",
      "initiating lsv list dict\n",
      "(1, 3, 32, 32)\n",
      "(1, 64, 32, 32)\n",
      "(1, 64, 32, 32)\n",
      "(1, 64, 32, 32)\n",
      "(1, 64, 32, 32)\n",
      "(1, 64, 32, 32)\n",
      "(1, 128, 16, 16)\n",
      "(1, 64, 32, 32)\n",
      "(1, 128, 16, 16)\n",
      "(1, 128, 16, 16)\n",
      "(1, 128, 16, 16)\n",
      "(1, 256, 8, 8)\n",
      "(1, 128, 16, 16)\n",
      "(1, 256, 8, 8)\n",
      "(1, 256, 8, 8)\n",
      "(1, 256, 8, 8)\n",
      "(1, 512, 4, 4)\n",
      "(1, 256, 8, 8)\n",
      "(1, 512, 4, 4)\n",
      "(1, 512, 4, 4)\n",
      "(1, 512)\n",
      "(1, 3, 32, 32)\n",
      "(1, 64, 32, 32)\n",
      "(1, 64, 32, 32)\n",
      "(1, 64, 32, 32)\n",
      "(1, 64, 32, 32)\n",
      "(1, 64, 32, 32)\n",
      "(1, 128, 16, 16)\n",
      "(1, 64, 32, 32)\n",
      "(1, 128, 16, 16)\n",
      "(1, 128, 16, 16)\n",
      "(1, 128, 16, 16)\n",
      "(1, 256, 8, 8)\n",
      "(1, 128, 16, 16)\n",
      "(1, 256, 8, 8)\n",
      "(1, 256, 8, 8)\n",
      "(1, 256, 8, 8)\n",
      "(1, 512, 4, 4)\n",
      "(1, 256, 8, 8)\n",
      "(1, 512, 4, 4)\n",
      "(1, 512, 4, 4)\n",
      "(1, 512)\n",
      "Epoch:  0 Loss:  4.1864485014343265 Loss_std:  4.1864485014343265 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  63.284117698669434\n",
      "Epoch:  1 Loss:  3.669177100982666 Loss_std:  3.669177100982666 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  53.78685164451599\n",
      "Epoch:  2 Loss:  3.2419018518066407 Loss_std:  3.2419018518066407 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  53.27736783027649\n",
      "Epoch:  3 Loss:  2.870859482574463 Loss_std:  2.870859482574463 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  52.0853066444397\n",
      "Epoch:  4 Loss:  2.6083108876037597 Loss_std:  2.6083108876037597 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  52.00377941131592\n",
      "Epoch:  5 Loss:  2.3564831037902834 Loss_std:  2.3564831037902834 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  51.812700033187866\n",
      "Epoch:  6 Loss:  2.181781126899719 Loss_std:  2.181781126899719 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  52.810773849487305\n",
      "Epoch:  7 Loss:  2.0076341716384887 Loss_std:  2.0076341716384887 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  51.97712230682373\n",
      "Epoch:  8 Loss:  1.900179169845581 Loss_std:  1.900179169845581 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  51.694171667099\n",
      "Epoch:  9 Loss:  1.7529439834594727 Loss_std:  1.7529439834594727 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  51.9015634059906\n",
      "Epoch:  10 Loss:  1.6695029732513427 Loss_std:  1.6695029732513427 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  50.82343530654907\n",
      "Epoch:  11 Loss:  1.581093476448059 Loss_std:  1.581093476448059 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  50.894466400146484\n",
      "Epoch:  12 Loss:  1.4998973058319092 Loss_std:  1.4998973058319092 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  51.909804821014404\n",
      "Epoch:  13 Loss:  1.4446886312866212 Loss_std:  1.4446886312866212 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  52.67381548881531\n",
      "Epoch:  14 Loss:  1.3977492602157593 Loss_std:  1.3977492602157593 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  54.14189314842224\n",
      "Epoch:  15 Loss:  1.3905799790573121 Loss_std:  1.3905799790573121 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  54.06144738197327\n",
      "Epoch:  16 Loss:  1.3308656916809083 Loss_std:  1.3308656916809083 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  55.09399461746216\n",
      "Epoch:  17 Loss:  1.3099336112976074 Loss_std:  1.3099336112976074 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  53.62018585205078\n",
      "Epoch:  18 Loss:  1.269950344696045 Loss_std:  1.269950344696045 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  53.78925681114197\n",
      "Epoch:  19 Loss:  1.2510694271850586 Loss_std:  1.2510694271850586 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  53.48700165748596\n",
      "Epoch:  20 Loss:  1.2247586518859863 Loss_std:  1.2247586518859863 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  54.332030296325684\n",
      "Epoch:  21 Loss:  1.204869518508911 Loss_std:  1.204869518508911 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  53.63443684577942\n",
      "Epoch:  22 Loss:  1.2074074231719971 Loss_std:  1.2074074231719971 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  53.20067763328552\n",
      "Epoch:  23 Loss:  1.169885309829712 Loss_std:  1.169885309829712 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  54.42767882347107\n",
      "Epoch:  24 Loss:  1.1383746852302552 Loss_std:  1.1383746852302552 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  54.39108920097351\n",
      "Epoch:  25 Loss:  1.127958024520874 Loss_std:  1.127958024520874 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  50.54887843132019\n",
      "Epoch:  26 Loss:  1.1232685110473632 Loss_std:  1.1232685110473632 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  52.92250084877014\n",
      "Epoch:  27 Loss:  1.1223349557495117 Loss_std:  1.1223349557495117 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  51.055548429489136\n",
      "Epoch:  28 Loss:  1.1222770987319945 Loss_std:  1.1222770987319945 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  51.09873700141907\n",
      "Epoch:  29 Loss:  1.098401187210083 Loss_std:  1.098401187210083 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  51.60952687263489\n",
      "Epoch:  30 Loss:  1.0477072479248046 Loss_std:  1.0477072479248046 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  49.93255591392517\n",
      "Epoch:  31 Loss:  1.0653616651916504 Loss_std:  1.0653616651916504 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  49.61081123352051\n",
      "Epoch:  32 Loss:  1.0740520753479004 Loss_std:  1.0740520753479004 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  50.66044616699219\n",
      "Epoch:  33 Loss:  1.0522028534698487 Loss_std:  1.0522028534698487 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  48.524476766586304\n",
      "Epoch:  34 Loss:  1.04031239528656 Loss_std:  1.04031239528656 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  51.94856262207031\n",
      "Epoch:  35 Loss:  1.0243429151916503 Loss_std:  1.0243429151916503 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  50.29253363609314\n",
      "Epoch:  36 Loss:  1.037244825706482 Loss_std:  1.037244825706482 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  52.093286752700806\n",
      "Epoch:  37 Loss:  1.0372121838378907 Loss_std:  1.0372121838378907 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  53.07673621177673\n",
      "Epoch:  38 Loss:  1.0150118027114867 Loss_std:  1.0150118027114867 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  50.92158627510071\n",
      "Epoch:  39 Loss:  1.0293621869659424 Loss_std:  1.0293621869659424 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  49.915608167648315\n",
      "Epoch:  40 Loss:  0.5867632607650757 Loss_std:  0.5867632607650757 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  52.040860176086426\n",
      "Epoch:  41 Loss:  0.4936085235595703 Loss_std:  0.4936085235595703 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  50.5349760055542\n",
      "Epoch:  42 Loss:  0.4616400907897949 Loss_std:  0.4616400907897949 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  51.052143573760986\n",
      "Epoch:  43 Loss:  0.45214728134155274 Loss_std:  0.45214728134155274 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  127.19277262687683\n",
      "Epoch:  44 Loss:  0.4315061684417725 Loss_std:  0.4315061684417725 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  154.25978660583496\n",
      "Epoch:  45 Loss:  0.42856240085601804 Loss_std:  0.42856240085601804 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  167.33812141418457\n",
      "Epoch:  46 Loss:  0.4143242305755615 Loss_std:  0.4143242305755615 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  192.7160713672638\n",
      "Epoch:  47 Loss:  0.41501512862205503 Loss_std:  0.41501512862205503 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  174.88234782218933\n",
      "Epoch:  48 Loss:  0.40567214292526244 Loss_std:  0.40567214292526244 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  176.08469200134277\n",
      "Epoch:  49 Loss:  0.3970662935256958 Loss_std:  0.3970662935256958 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  177.12897396087646\n",
      "Epoch:  50 Loss:  0.38998490951538084 Loss_std:  0.38998490951538084 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  180.23774027824402\n",
      "Epoch:  51 Loss:  0.388362601852417 Loss_std:  0.388362601852417 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  174.1161653995514\n",
      "Epoch:  52 Loss:  0.3823388451862335 Loss_std:  0.3823388451862335 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  192.35000276565552\n",
      "Epoch:  53 Loss:  0.3828554210281372 Loss_std:  0.3828554210281372 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  190.9775173664093\n",
      "Epoch:  54 Loss:  0.3774403766345978 Loss_std:  0.3774403766345978 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  184.06841230392456\n",
      "Epoch:  55 Loss:  0.3624567310810089 Loss_std:  0.3624567310810089 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  184.94955134391785\n",
      "Epoch:  56 Loss:  0.36536567792892455 Loss_std:  0.36536567792892455 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  186.46142601966858\n",
      "Epoch:  57 Loss:  0.35448529834747317 Loss_std:  0.35448529834747317 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  168.27616000175476\n",
      "Epoch:  58 Loss:  0.35734830198287965 Loss_std:  0.35734830198287965 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  183.04363632202148\n",
      "Epoch:  59 Loss:  0.34650790426254274 Loss_std:  0.34650790426254274 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  186.39343523979187\n",
      "Epoch:  60 Loss:  0.34310734510421753 Loss_std:  0.34310734510421753 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  184.8813464641571\n",
      "0 0 0.7734515260323159\n",
      "model:  0 6636  out of  10000\n",
      "0 1 0.8050030138637734\n",
      "model:  1 6428  out of  10000\n",
      "1 0 0.8592097075295582\n",
      "1 1 0.7535925142029631\n",
      "Epoch:  61 Loss:  0.34237333280563353 Loss_std:  0.34237333280563353 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  289.7955038547516\n",
      "Epoch:  62 Loss:  0.3384685656356812 Loss_std:  0.3384685656356812 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  208.5239861011505\n",
      "Epoch:  63 Loss:  0.3202063458442688 Loss_std:  0.3202063458442688 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  202.35829877853394\n",
      "Epoch:  64 Loss:  0.32362155395507813 Loss_std:  0.32362155395507813 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  163.1722891330719\n",
      "Epoch:  65 Loss:  0.31954747921943666 Loss_std:  0.31954747921943666 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  188.82496237754822\n",
      "Epoch:  66 Loss:  0.32122933223724365 Loss_std:  0.32122933223724365 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  185.74941229820251\n",
      "Epoch:  67 Loss:  0.30935777433395384 Loss_std:  0.30935777433395384 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  177.0277762413025\n",
      "Epoch:  68 Loss:  0.3148637652730942 Loss_std:  0.3148637652730942 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  201.8381097316742\n",
      "Epoch:  69 Loss:  0.3006202885723114 Loss_std:  0.3006202885723114 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  187.5720112323761\n",
      "Epoch:  70 Loss:  0.3025743112373352 Loss_std:  0.3025743112373352 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  175.94540429115295\n",
      "Epoch:  71 Loss:  0.30216405233860016 Loss_std:  0.30216405233860016 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  196.2656581401825\n",
      "Epoch:  72 Loss:  0.2934620984697342 Loss_std:  0.2934620984697342 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  181.1280632019043\n",
      "Epoch:  73 Loss:  0.3015369541549683 Loss_std:  0.3015369541549683 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  175.2527232170105\n",
      "Epoch:  74 Loss:  0.2877693495178223 Loss_std:  0.2877693495178223 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  192.77568078041077\n",
      "Epoch:  75 Loss:  0.2824119198393822 Loss_std:  0.2824119198393822 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  189.46921467781067\n",
      "Epoch:  76 Loss:  0.2747828991317749 Loss_std:  0.2747828991317749 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  178.89326167106628\n",
      "Epoch:  77 Loss:  0.2830762664604187 Loss_std:  0.2830762664604187 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  55.64878273010254\n",
      "Epoch:  78 Loss:  0.272143119430542 Loss_std:  0.272143119430542 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  56.977481842041016\n",
      "Epoch:  79 Loss:  0.26903222295284274 Loss_std:  0.26903222295284274 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  53.94720458984375\n",
      "Epoch:  80 Loss:  0.1590762666606903 Loss_std:  0.1590762666606903 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  53.83170032501221\n",
      "0 0 0.7256887727322225\n",
      "model:  0 6484  out of  10000\n",
      "0 1 0.857649599012955\n",
      "model:  1 6590  out of  10000\n",
      "1 0 0.8371775417298938\n",
      "1 1 0.7375516416612307\n",
      "Epoch:  81 Loss:  0.14460394311666488 Loss_std:  0.14460394311666488 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  56.323569774627686\n",
      "Epoch:  82 Loss:  0.14764833547592163 Loss_std:  0.14764833547592163 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  54.68569087982178\n",
      "Epoch:  83 Loss:  0.1548925931453705 Loss_std:  0.1548925931453705 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  54.101125717163086\n",
      "Epoch:  84 Loss:  0.1611793771314621 Loss_std:  0.1611793771314621 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  53.119279623031616\n",
      "Epoch:  85 Loss:  0.17051568462371827 Loss_std:  0.17051568462371827 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  53.620635986328125\n",
      "Epoch:  86 Loss:  0.1798215264558792 Loss_std:  0.1798215264558792 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  54.20244741439819\n",
      "Epoch:  87 Loss:  0.18839480348587037 Loss_std:  0.18839480348587037 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  54.553926944732666\n",
      "Epoch:  88 Loss:  0.1962990180683136 Loss_std:  0.1962990180683136 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  52.835241079330444\n",
      "Epoch:  89 Loss:  0.2041330880880356 Loss_std:  0.2041330880880356 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  53.47293186187744\n",
      "Epoch:  90 Loss:  0.2111204925060272 Loss_std:  0.2111204925060272 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  53.11366653442383\n",
      "Epoch:  91 Loss:  0.22133691197395325 Loss_std:  0.22133691197395325 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  52.32819604873657\n",
      "Epoch:  92 Loss:  0.22545090447425842 Loss_std:  0.22545090447425842 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  52.492090702056885\n",
      "Epoch:  93 Loss:  0.23247092041015624 Loss_std:  0.23247092041015624 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  52.61198568344116\n",
      "Epoch:  94 Loss:  0.24065477975845337 Loss_std:  0.24065477975845337 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  54.30717420578003\n",
      "Epoch:  95 Loss:  0.2394745781326294 Loss_std:  0.2394745781326294 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  54.01620268821716\n",
      "Epoch:  96 Loss:  0.24634305695533754 Loss_std:  0.24634305695533754 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  53.101357221603394\n",
      "Epoch:  97 Loss:  0.250629842710495 Loss_std:  0.250629842710495 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  53.20715856552124\n",
      "Epoch:  98 Loss:  0.25301310548782346 Loss_std:  0.25301310548782346 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  53.84316039085388\n",
      "Epoch:  99 Loss:  0.25360282512664795 Loss_std:  0.25360282512664795 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  56.36685919761658\n",
      "Epoch:  100 Loss:  0.2571161867332459 Loss_std:  0.2571161867332459 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  52.587027072906494\n",
      "0 0 0.6760159010600707\n",
      "model:  0 5913  out of  10000\n",
      "0 1 0.8733299509555217\n",
      "model:  1 5991  out of  10000\n",
      "1 0 0.8594558504423302\n",
      "1 1 0.6838202744577246\n",
      "Epoch:  101 Loss:  0.2559823592662811 Loss_std:  0.2559823592662811 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  57.00588846206665\n",
      "Epoch:  102 Loss:  0.2627807198143005 Loss_std:  0.2627807198143005 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  54.77845001220703\n",
      "Epoch:  103 Loss:  0.26014113132476807 Loss_std:  0.26014113132476807 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  53.730172634124756\n",
      "Epoch:  104 Loss:  0.25783451787471773 Loss_std:  0.25783451787471773 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  52.27882695198059\n",
      "Epoch:  105 Loss:  0.25735458318710325 Loss_std:  0.25735458318710325 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  53.78609323501587\n",
      "Epoch:  106 Loss:  0.2619797790813446 Loss_std:  0.2619797790813446 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  53.903958320617676\n",
      "Epoch:  107 Loss:  0.2640436267852783 Loss_std:  0.2640436267852783 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  56.26916193962097\n",
      "Epoch:  108 Loss:  0.2642053329181671 Loss_std:  0.2642053329181671 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  53.96286392211914\n",
      "Epoch:  109 Loss:  0.26313733398914335 Loss_std:  0.26313733398914335 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  52.76270270347595\n",
      "Epoch:  110 Loss:  0.2671158131980896 Loss_std:  0.2671158131980896 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  55.05145215988159\n",
      "Epoch:  111 Loss:  0.2619435788631439 Loss_std:  0.2619435788631439 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  53.01592302322388\n",
      "Epoch:  112 Loss:  0.26506265354156494 Loss_std:  0.26506265354156494 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  54.65528702735901\n",
      "Epoch:  113 Loss:  0.2650089246559143 Loss_std:  0.2650089246559143 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  55.638890981674194\n",
      "Epoch:  114 Loss:  0.26448535976409915 Loss_std:  0.26448535976409915 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  55.50161600112915\n",
      "Epoch:  115 Loss:  0.2636146560239792 Loss_std:  0.2636146560239792 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  55.26012873649597\n",
      "Epoch:  116 Loss:  0.26489663735389707 Loss_std:  0.26489663735389707 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  54.405407428741455\n",
      "Epoch:  117 Loss:  0.26568381983757017 Loss_std:  0.26568381983757017 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  54.08041429519653\n",
      "Epoch:  118 Loss:  0.2658445853090286 Loss_std:  0.2658445853090286 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  55.36613416671753\n",
      "Epoch:  119 Loss:  0.2582279135131836 Loss_std:  0.2582279135131836 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  54.74906945228577\n",
      "Epoch:  120 Loss:  0.24410276395797728 Loss_std:  0.24410276395797728 Ortho_loss:  0 ortho total: 0.0\n",
      "time:  55.329017877578735\n",
      "0 0 0.6631428256799912\n",
      "model:  0 5852  out of  10000\n",
      "0 1 0.8673957621326043\n",
      "model:  1 5809  out of  10000\n",
      "1 0 0.8841452917886039\n",
      "1 1 0.659410729991205\n"
     ]
    }
   ],
   "source": [
    "df_clip = train_ensemble(num_models, clip_flag=True, lotos_flag=False, seed_val=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "!!!!!!! Clipping is active !!!!!!!! clip val:  1.0\n",
      "def iter:  1\n",
      "opt step size:  0.35\n",
      "Model loaded\n",
      "initiating lsv list dict\n",
      "(1, 3, 32, 32)\n",
      "(1, 64, 32, 32)\n",
      "(1, 64, 32, 32)\n",
      "(1, 64, 32, 32)\n",
      "(1, 64, 32, 32)\n",
      "(1, 64, 32, 32)\n",
      "(1, 128, 16, 16)\n",
      "(1, 64, 32, 32)\n",
      "(1, 128, 16, 16)\n",
      "(1, 128, 16, 16)\n",
      "(1, 128, 16, 16)\n",
      "(1, 256, 8, 8)\n",
      "(1, 128, 16, 16)\n",
      "(1, 256, 8, 8)\n",
      "(1, 256, 8, 8)\n",
      "(1, 256, 8, 8)\n",
      "(1, 512, 4, 4)\n",
      "(1, 256, 8, 8)\n",
      "(1, 512, 4, 4)\n",
      "(1, 512, 4, 4)\n",
      "(1, 512)\n",
      "(1, 3, 32, 32)\n",
      "(1, 64, 32, 32)\n",
      "(1, 64, 32, 32)\n",
      "(1, 64, 32, 32)\n",
      "(1, 64, 32, 32)\n",
      "(1, 64, 32, 32)\n",
      "(1, 128, 16, 16)\n",
      "(1, 64, 32, 32)\n",
      "(1, 128, 16, 16)\n",
      "(1, 128, 16, 16)\n",
      "(1, 128, 16, 16)\n",
      "(1, 256, 8, 8)\n",
      "(1, 128, 16, 16)\n",
      "(1, 256, 8, 8)\n",
      "(1, 256, 8, 8)\n",
      "(1, 256, 8, 8)\n",
      "(1, 512, 4, 4)\n",
      "(1, 256, 8, 8)\n",
      "(1, 512, 4, 4)\n",
      "(1, 512, 4, 4)\n",
      "(1, 512)\n",
      "Epoch:  0 Loss:  4.253640408706665 Loss_std:  4.23583936378479 Ortho_loss:  0 ortho total: 6.953533229231834\n",
      "time:  74.5362069606781\n",
      "Epoch:  1 Loss:  3.8291101988220215 Loss_std:  3.8107550889587403 Ortho_loss:  0 ortho total: 7.1699660956859566\n",
      "time:  66.87484669685364\n",
      "pairs 1.0 conv 20 ortho loss conv:  0.13836462795734406\n",
      "Epoch:  2 Loss:  3.4818225975036623 Loss_std:  3.4638519859313965 Ortho_loss:  0 ortho total: 7.019769257307046\n",
      "time:  65.69941544532776\n",
      "Epoch:  3 Loss:  3.118406932220459 Loss_std:  3.111485997772217 Ortho_loss:  0 ortho total: 2.7034893274307246\n",
      "time:  65.7719476222992\n",
      "Epoch:  4 Loss:  2.8160648515319826 Loss_std:  2.809497911224365 Ortho_loss:  0 ortho total: 2.565209293365479\n",
      "time:  67.24068236351013\n",
      "pairs 1.0 conv 20 ortho loss conv:  0.07846409678459168\n",
      "Epoch:  5 Loss:  2.5211754200744627 Loss_std:  2.5152484364318846 Ortho_loss:  0 ortho total: 2.315227514505387\n",
      "time:  66.23385238647461\n",
      "Epoch:  6 Loss:  2.2781909057998657 Loss_std:  2.2680475009536742 Ortho_loss:  0 ortho total: 3.9622690021991755\n",
      "time:  66.97798037528992\n",
      "pairs 1.0 conv 20 ortho loss conv:  0.09545580446720124\n",
      "Epoch:  7 Loss:  2.090178355560303 Loss_std:  2.0758829093933104 Ortho_loss:  0 ortho total: 5.584157222509381\n",
      "time:  67.19075345993042\n",
      "Epoch:  8 Loss:  1.9316510552978516 Loss_std:  1.9225320785522462 Ortho_loss:  0 ortho total: 3.5621007621288276\n",
      "time:  67.20740056037903\n",
      "Epoch:  9 Loss:  1.8427518814849853 Loss_std:  1.832162268447876 Ortho_loss:  0 ortho total: 4.136567789316178\n",
      "time:  66.07105350494385\n",
      "pairs 1.0 conv 20 ortho loss conv:  0.0649238407611847\n",
      "Epoch:  10 Loss:  1.7471708081436157 Loss_std:  1.7399379486465454 Ortho_loss:  0 ortho total: 2.825334903597831\n",
      "time:  65.73583817481995\n",
      "Epoch:  11 Loss:  1.6732741709899903 Loss_std:  1.6614675218200683 Ortho_loss:  0 ortho total: 4.611972323060035\n",
      "time:  64.2528178691864\n",
      "pairs 1.0 conv 20 ortho loss conv:  0.16340439915657043\n",
      "Epoch:  12 Loss:  1.5932247577667236 Loss_std:  1.5822007975006103 Ortho_loss:  0 ortho total: 4.306234404444696\n",
      "time:  65.03972482681274\n",
      "Epoch:  13 Loss:  1.557699432296753 Loss_std:  1.5441911577606202 Ortho_loss:  0 ortho total: 5.276669400930405\n",
      "time:  64.79272794723511\n",
      "Epoch:  14 Loss:  1.5030586798858643 Loss_std:  1.4923325659942628 Ortho_loss:  0 ortho total: 4.1898892551660545\n",
      "time:  64.55924916267395\n",
      "pairs 1.0 conv 20 ortho loss conv:  0.10722504854202271\n",
      "Epoch:  15 Loss:  1.469603734741211 Loss_std:  1.4561956719970703 Ortho_loss:  0 ortho total: 5.237523686885833\n",
      "time:  66.39039921760559\n",
      "Epoch:  16 Loss:  1.4351483698654175 Loss_std:  1.4211507746505738 Ortho_loss:  0 ortho total: 5.467810913920406\n",
      "time:  65.57960367202759\n",
      "pairs 1.0 conv 20 ortho loss conv:  0.08228264451026918\n",
      "Epoch:  17 Loss:  1.407822242050171 Loss_std:  1.395334742050171 Ortho_loss:  0 ortho total: 4.877930033206941\n",
      "time:  66.1652672290802\n",
      "Epoch:  18 Loss:  1.3993823894500732 Loss_std:  1.3894344744110108 Ortho_loss:  0 ortho total: 3.8859043657779693\n",
      "time:  64.37933254241943\n",
      "Epoch:  19 Loss:  1.3490988443756105 Loss_std:  1.3343980681610108 Ortho_loss:  0 ortho total: 5.7424898386001635\n",
      "time:  65.059406042099\n",
      "pairs 1.0 conv 20 ortho loss conv:  0.07585401237010957\n",
      "Epoch:  20 Loss:  1.329837886505127 Loss_std:  1.320653364868164 Ortho_loss:  0 ortho total: 3.5877046674489983\n",
      "time:  62.58623218536377\n",
      "Epoch:  21 Loss:  1.2990483292007446 Loss_std:  1.2866201739883423 Ortho_loss:  0 ortho total: 4.854748651385307\n",
      "time:  65.63064527511597\n",
      "Epoch:  22 Loss:  1.3179177590560913 Loss_std:  1.3058777405929565 Ortho_loss:  0 ortho total: 4.703133016824716\n",
      "time:  62.991392612457275\n",
      "pairs 1.0 conv 20 ortho loss conv:  0.06805765032768249\n",
      "Epoch:  23 Loss:  1.2863669457435607 Loss_std:  1.2741921805763246 Ortho_loss:  0 ortho total: 4.755767437815671\n",
      "time:  65.12885618209839\n",
      "Epoch:  24 Loss:  1.2694241581726073 Loss_std:  1.2573970558166503 Ortho_loss:  0 ortho total: 4.69808695912361\n",
      "time:  65.11081671714783\n",
      "pairs 1.0 conv 20 ortho loss conv:  0.06597244739532472\n",
      "Epoch:  25 Loss:  1.2585150570678711 Loss_std:  1.2482694425964356 Ortho_loss:  0 ortho total: 4.0021940737962725\n",
      "time:  65.3660306930542\n",
      "Epoch:  26 Loss:  1.2490051815032959 Loss_std:  1.238217071762085 Ortho_loss:  0 ortho total: 4.214104819297787\n",
      "time:  65.51939511299133\n",
      "Epoch:  27 Loss:  1.2511744580078126 Loss_std:  1.2355687258911132 Ortho_loss:  0 ortho total: 6.095989081263542\n",
      "time:  68.54899287223816\n",
      "pairs 1.0 conv 20 ortho loss conv:  0.10451749563217165\n",
      "Epoch:  28 Loss:  1.2397788945007324 Loss_std:  1.225406153717041 Ortho_loss:  0 ortho total: 5.61435110270977\n",
      "time:  68.87769150733948\n",
      "Epoch:  29 Loss:  1.231328298110962 Loss_std:  1.2184200244903565 Ortho_loss:  0 ortho total: 5.042294436693192\n",
      "time:  69.56724381446838\n",
      "pairs 1.0 conv 20 ortho loss conv:  0.06288567781448366\n",
      "Epoch:  30 Loss:  1.189299523086548 Loss_std:  1.1789563861846923 Ortho_loss:  0 ortho total: 4.040288209915162\n",
      "time:  67.9966037273407\n",
      "Epoch:  31 Loss:  1.1870476974868776 Loss_std:  1.1775462842178346 Ortho_loss:  0 ortho total: 3.7114902198314668\n",
      "time:  69.1599349975586\n",
      "Epoch:  32 Loss:  1.1939228342819215 Loss_std:  1.1877591013717652 Ortho_loss:  0 ortho total: 2.407709607481957\n",
      "time:  68.8208589553833\n",
      "pairs 1.0 conv 20 ortho loss conv:  0.08359830379486084\n",
      "Epoch:  33 Loss:  1.1911570615005493 Loss_std:  1.1788402324295044 Ortho_loss:  0 ortho total: 4.811262178421022\n",
      "time:  67.50270438194275\n",
      "Epoch:  34 Loss:  1.1630025157165527 Loss_std:  1.1498671041870117 Ortho_loss:  0 ortho total: 5.1310186147689825\n",
      "time:  69.47490382194519\n",
      "pairs 1.0 conv 20 ortho loss conv:  0.07556947767734529\n",
      "Epoch:  35 Loss:  1.1519863009643554 Loss_std:  1.140019578704834 Ortho_loss:  0 ortho total: 4.674500507116316\n",
      "time:  68.38451433181763\n",
      "Epoch:  36 Loss:  1.1342829681015014 Loss_std:  1.1252990438461303 Ortho_loss:  0 ortho total: 3.509345814585685\n",
      "time:  67.11433625221252\n",
      "Epoch:  37 Loss:  1.1557384781265259 Loss_std:  1.1462753622817994 Ortho_loss:  0 ortho total: 3.6965289890766115\n",
      "time:  66.61446642875671\n",
      "pairs 1.0 conv 20 ortho loss conv:  0.10678632855415345\n",
      "Epoch:  38 Loss:  1.1568635172271728 Loss_std:  1.1473421506500243 Ortho_loss:  0 ortho total: 3.7192838907241845\n",
      "time:  64.53267097473145\n",
      "Epoch:  39 Loss:  1.138163949584961 Loss_std:  1.1273492636108398 Ortho_loss:  0 ortho total: 4.224486601352692\n",
      "time:  64.08528280258179\n",
      "pairs 1.0 conv 20 ortho loss conv:  0.05259090960025788\n",
      "Epoch:  40 Loss:  0.6896066047096252 Loss_std:  0.6798672336769104 Ortho_loss:  0 ortho total: 3.8044412612915037\n",
      "time:  61.40041732788086\n",
      "Epoch:  41 Loss:  0.6057844869995117 Loss_std:  0.5914835665893554 Ortho_loss:  0 ortho total: 5.586297175288204\n",
      "time:  64.7278242111206\n",
      "Epoch:  42 Loss:  0.5655069355773926 Loss_std:  0.5564999490356445 Ortho_loss:  0 ortho total: 3.5183545529842393\n",
      "time:  64.1340184211731\n",
      "pairs 1.0 conv 20 ortho loss conv:  0.012078395485877991\n",
      "Epoch:  43 Loss:  0.5594469767761231 Loss_std:  0.5515199123382568 Ortho_loss:  0 ortho total: 3.0965095907449713\n",
      "time:  62.56953740119934\n",
      "Epoch:  44 Loss:  0.5336039826583863 Loss_std:  0.5308730055618286 Ortho_loss:  0 ortho total: 1.0667880058288572\n",
      "time:  62.45523762702942\n",
      "Epoch:  45 Loss:  0.5202711075687408 Loss_std:  0.517233695306778 Ortho_loss:  0 ortho total: 1.1864893496036533\n",
      "time:  63.05699300765991\n",
      "pairs 1.0 conv 20 ortho loss conv:  0.012919333577156068\n",
      "Epoch:  46 Loss:  0.5107035327720643 Loss_std:  0.5064818949699402 Ortho_loss:  0 ortho total: 1.649077326059342\n",
      "time:  62.51625871658325\n",
      "Epoch:  47 Loss:  0.5064886183357239 Loss_std:  0.5032569300270081 Ortho_loss:  0 ortho total: 1.2623783528804768\n",
      "time:  61.87792730331421\n",
      "pairs 1.0 conv 20 ortho loss conv:  0.02228955626487732\n",
      "Epoch:  48 Loss:  0.48929343307495116 Loss_std:  0.48461711753845216 Ortho_loss:  0 ortho total: 1.826685598492623\n",
      "time:  62.60677456855774\n",
      "Epoch:  49 Loss:  0.48395822490692136 Loss_std:  0.4755919150924683 Ortho_loss:  0 ortho total: 3.2680900633335126\n",
      "time:  63.07398438453674\n",
      "Epoch:  50 Loss:  0.47304780918121336 Loss_std:  0.4692993872833252 Ortho_loss:  0 ortho total: 1.4642273902893066\n",
      "time:  62.10841608047485\n",
      "pairs 1.0 conv 20 ortho loss conv:  0.015181991457939149\n",
      "Epoch:  51 Loss:  0.46228815784454347 Loss_std:  0.4573974676513672 Ortho_loss:  0 ortho total: 1.9104260802268986\n",
      "time:  61.840288162231445\n",
      "Epoch:  52 Loss:  0.4594860516166687 Loss_std:  0.45658051500320435 Ortho_loss:  0 ortho total: 1.1349751174449914\n",
      "time:  63.012555837631226\n",
      "pairs 1.0 conv 20 ortho loss conv:  0.015733307600021364\n",
      "Epoch:  53 Loss:  0.4517492774772644 Loss_std:  0.44889561609268186 Ortho_loss:  0 ortho total: 1.1147118210792542\n",
      "time:  62.116705656051636\n",
      "Epoch:  54 Loss:  0.4446813463973999 Loss_std:  0.4424805704498291 Ortho_loss:  0 ortho total: 0.8596782624721527\n",
      "time:  63.81143140792847\n",
      "Epoch:  55 Loss:  0.42727341059684754 Loss_std:  0.42500863837242125 Ortho_loss:  0 ortho total: 0.8846767157316207\n",
      "time:  63.48987674713135\n",
      "pairs 1.0 conv 20 ortho loss conv:  0.019573915004730227\n",
      "Epoch:  56 Loss:  0.4248005125045776 Loss_std:  0.4229709297180176 Ortho_loss:  0 ortho total: 0.7146808087825773\n",
      "time:  65.4319200515747\n",
      "Epoch:  57 Loss:  0.41953665477752683 Loss_std:  0.41618772277832033 Ortho_loss:  0 ortho total: 1.30817663371563\n",
      "time:  64.18018388748169\n",
      "pairs 1.0 conv 20 ortho loss conv:  0.025961834192276004\n",
      "Epoch:  58 Loss:  0.41870356227874755 Loss_std:  0.4149912354660034 Ortho_loss:  0 ortho total: 1.4501277416944505\n",
      "time:  64.95255875587463\n",
      "Epoch:  59 Loss:  0.4051256309318543 Loss_std:  0.4032598349571228 Ortho_loss:  0 ortho total: 0.7288266479969024\n",
      "time:  64.21547985076904\n",
      "Epoch:  60 Loss:  0.40066507402420043 Loss_std:  0.3991370899581909 Ortho_loss:  0 ortho total: 0.5968689620494843\n",
      "time:  65.26676106452942\n",
      "0 0 0.7193042291950886\n",
      "model:  0 5965  out of  10000\n",
      "0 1 0.6219614417435038\n",
      "model:  1 6711  out of  10000\n",
      "1 0 0.515124422589778\n",
      "1 1 0.8081961706415854\n",
      "pairs 1.0 conv 20 ortho loss conv:  0.030213218927383424\n",
      "Epoch:  61 Loss:  0.3934704496002197 Loss_std:  0.3903060353851318 Ortho_loss:  0 ortho total: 1.2360994815826412\n",
      "time:  68.96358704566956\n",
      "Epoch:  62 Loss:  0.38958947435379027 Loss_std:  0.3867174850654602 Ortho_loss:  0 ortho total: 1.121870777010918\n",
      "time:  64.66393899917603\n",
      "pairs 1.0 conv 20 ortho loss conv:  0.009166607260704042\n",
      "Epoch:  63 Loss:  0.37456665292739866 Loss_std:  0.372846586856842 Ortho_loss:  0 ortho total: 0.671900781989097\n",
      "time:  65.89724564552307\n",
      "Epoch:  64 Loss:  0.37765925315856935 Loss_std:  0.3752650768661499 Ortho_loss:  0 ortho total: 0.9352250307798384\n",
      "time:  65.86639976501465\n",
      "Epoch:  65 Loss:  0.377832440533638 Loss_std:  0.3751428346681595 Ortho_loss:  0 ortho total: 1.0506273925304415\n",
      "time:  64.84857058525085\n",
      "pairs 1.0 conv 20 ortho loss conv:  0.018882259726524353\n",
      "Epoch:  66 Loss:  0.3649837712097168 Loss_std:  0.36194527946472166 Ortho_loss:  0 ortho total: 1.1869108259677885\n",
      "time:  63.374640703201294\n",
      "Epoch:  67 Loss:  0.3614457202529907 Loss_std:  0.35827203197479246 Ortho_loss:  0 ortho total: 1.2397219121456144\n",
      "time:  63.80646085739136\n",
      "Epoch:  68 Loss:  0.3621912918901444 Loss_std:  0.36048113815784455 Ortho_loss:  0 ortho total: 0.6680288523435594\n",
      "time:  65.084876537323\n",
      "pairs 1.0 conv 20 ortho loss conv:  0.025588458776474005\n",
      "Epoch:  69 Loss:  0.34943370129585266 Loss_std:  0.34601513436317444 Ortho_loss:  0 ortho total: 1.33537794649601\n",
      "time:  64.20460748672485\n",
      "Epoch:  70 Loss:  0.35519020002365115 Loss_std:  0.3528989476966858 Ortho_loss:  0 ortho total: 0.895020398497581\n",
      "time:  66.08926224708557\n",
      "pairs 1.0 conv 20 ortho loss conv:  0.018256908655166625\n",
      "Epoch:  71 Loss:  0.3434042537784576 Loss_std:  0.33999347992897033 Ortho_loss:  0 ortho total: 1.332333692908287\n",
      "time:  64.26646852493286\n",
      "Epoch:  72 Loss:  0.3345186832714081 Loss_std:  0.3320052126598358 Ortho_loss:  0 ortho total: 0.9818245321512229\n",
      "time:  64.5814380645752\n",
      "Epoch:  73 Loss:  0.3394444387531281 Loss_std:  0.336929694852829 Ortho_loss:  0 ortho total: 0.982321825623512\n",
      "time:  65.15872478485107\n",
      "pairs 1.0 conv 20 ortho loss conv:  0.021865910291671755\n",
      "Epoch:  74 Loss:  0.33262391849517825 Loss_std:  0.33064131187438967 Ortho_loss:  0 ortho total: 0.7744556158781052\n",
      "time:  66.61136794090271\n",
      "Epoch:  75 Loss:  0.33119696870803833 Loss_std:  0.3285230994987488 Ortho_loss:  0 ortho total: 1.0444800496101379\n",
      "time:  65.57466101646423\n",
      "pairs 1.0 conv 20 ortho loss conv:  0.021425139904022217\n",
      "Epoch:  76 Loss:  0.31253778276443483 Loss_std:  0.30897778562545775 Ortho_loss:  0 ortho total: 1.3906240463256836\n",
      "time:  65.0926079750061\n",
      "Epoch:  77 Loss:  0.32543295948028567 Loss_std:  0.3236174110794067 Ortho_loss:  0 ortho total: 0.7091986477375033\n",
      "time:  64.16442441940308\n",
      "Epoch:  78 Loss:  0.31056478830337525 Loss_std:  0.30815820177078246 Ortho_loss:  0 ortho total: 0.9400728553533557\n",
      "time:  64.88677477836609\n",
      "pairs 1.0 conv 20 ortho loss conv:  0.014666110277175905\n",
      "Epoch:  79 Loss:  0.30914945950508116 Loss_std:  0.3071737490749359 Ortho_loss:  0 ortho total: 0.7717617869377136\n",
      "time:  65.70298647880554\n",
      "Epoch:  80 Loss:  0.184544945230484 Loss_std:  0.1774178578853607 Ortho_loss:  0 ortho total: 2.784018394351004\n",
      "time:  67.84074687957764\n",
      "0 0 0.7082269346064173\n",
      "model:  0 6119  out of  10000\n",
      "0 1 0.6190554012093479\n",
      "model:  1 6784  out of  10000\n",
      "1 0 0.5459905660377359\n",
      "1 1 0.7850508141186755\n",
      "pairs 1.0 conv 20 ortho loss conv:  0.010053223371505738\n",
      "Epoch:  81 Loss:  0.16562568953990936 Loss_std:  0.16089726653575898 Ortho_loss:  0 ortho total: 1.8470401912927634\n",
      "time:  71.60331082344055\n",
      "Epoch:  82 Loss:  0.16688075618743897 Loss_std:  0.16437013256073 Ortho_loss:  0 ortho total: 0.9807122379541399\n",
      "time:  66.28427863121033\n",
      "Epoch:  83 Loss:  0.1777323221874237 Loss_std:  0.1714860888004303 Ortho_loss:  0 ortho total: 2.4399349272251123\n",
      "time:  68.2524311542511\n",
      "pairs 1.0 conv 20 ortho loss conv:  0.01677427887916565\n",
      "Epoch:  84 Loss:  0.1837730327320099 Loss_std:  0.17626202094078064 Ortho_loss:  0 ortho total: 2.93398889005184\n",
      "time:  68.7445330619812\n",
      "Epoch:  85 Loss:  0.19517207041740417 Loss_std:  0.18929236365318297 Ortho_loss:  0 ortho total: 2.2967603325843804\n",
      "time:  67.56333374977112\n",
      "pairs 1.0 conv 20 ortho loss conv:  0.020302429795265198\n",
      "Epoch:  86 Loss:  0.20511314687728882 Loss_std:  0.19721979839324952 Ortho_loss:  0 ortho total: 3.0833392858505264\n",
      "time:  67.53020405769348\n",
      "Epoch:  87 Loss:  0.2165360249519348 Loss_std:  0.20368978807449342 Ortho_loss:  0 ortho total: 5.018061226606368\n",
      "time:  67.67323017120361\n",
      "Epoch:  88 Loss:  0.21516765397548676 Loss_std:  0.21072785724163057 Ortho_loss:  0 ortho total: 1.7342955529689785\n",
      "time:  64.11387038230896\n",
      "pairs 1.0 conv 20 ortho loss conv:  0.01582932472229004\n",
      "Epoch:  89 Loss:  0.2261969390296936 Loss_std:  0.21760767766952516 Ortho_loss:  0 ortho total: 3.355180165171623\n",
      "time:  65.38943910598755\n",
      "Epoch:  90 Loss:  0.23000703858375549 Loss_std:  0.22363451994895936 Ortho_loss:  0 ortho total: 2.4892650693654996\n",
      "time:  67.10688614845276\n",
      "Epoch:  91 Loss:  0.24131794214248659 Loss_std:  0.23570269674301148 Ortho_loss:  0 ortho total: 2.1934552550315853\n",
      "time:  66.9729573726654\n",
      "pairs 1.0 conv 20 ortho loss conv:  0.005140918493270874\n",
      "Epoch:  92 Loss:  0.24564198263168335 Loss_std:  0.23917812101364136 Ortho_loss:  0 ortho total: 2.5249459564685814\n",
      "time:  65.53731989860535\n",
      "Epoch:  93 Loss:  0.24982906462669371 Loss_std:  0.24306643633842467 Ortho_loss:  0 ortho total: 2.6416515499353395\n",
      "time:  65.54383063316345\n",
      "pairs 1.0 conv 20 ortho loss conv:  0.005815654993057251\n",
      "Epoch:  94 Loss:  0.25263953343868256 Loss_std:  0.24732063064098359 Ortho_loss:  0 ortho total: 2.077696585655212\n",
      "time:  66.88006067276001\n",
      "Epoch:  95 Loss:  0.2577725823307037 Loss_std:  0.2504762971401215 Ortho_loss:  0 ortho total: 2.8501114070415494\n",
      "time:  65.33708477020264\n",
      "Epoch:  96 Loss:  0.25501132772922513 Loss_std:  0.24889875856876373 Ortho_loss:  0 ortho total: 2.3877223491668715\n",
      "time:  69.83028149604797\n",
      "pairs 1.0 conv 20 ortho loss conv:  0.004316315054893494\n",
      "Epoch:  97 Loss:  0.2613712487125397 Loss_std:  0.255387222032547 Ortho_loss:  0 ortho total: 2.3375104963779467\n",
      "time:  67.95450353622437\n",
      "Epoch:  98 Loss:  0.26005342253685 Loss_std:  0.2552447983455658 Ortho_loss:  0 ortho total: 1.8783688992261873\n",
      "time:  66.44257116317749\n",
      "pairs 1.0 conv 20 ortho loss conv:  0.0028160035610198977\n",
      "Epoch:  99 Loss:  0.25940702889442446 Loss_std:  0.253390329618454 Ortho_loss:  0 ortho total: 2.3502731323242156\n",
      "time:  68.07894372940063\n",
      "Epoch:  100 Loss:  0.2631379973125458 Loss_std:  0.2582402617931366 Ortho_loss:  0 ortho total: 1.9131780236959461\n",
      "time:  67.32392406463623\n",
      "0 0 0.6602860038283977\n",
      "model:  0 5595  out of  10000\n",
      "0 1 0.6518319928507597\n",
      "model:  1 5952  out of  10000\n",
      "1 0 0.6436491935483871\n",
      "1 1 0.707517793594306\n",
      "Epoch:  101 Loss:  0.26619259766578673 Loss_std:  0.2593840334033966 Ortho_loss:  0 ortho total: 2.6595952838659276\n",
      "time:  71.68000102043152\n",
      "pairs 1.0 conv 20 ortho loss conv:  0.003257963061332703\n",
      "Epoch:  102 Loss:  0.2668212899589539 Loss_std:  0.26146612005233766 Ortho_loss:  0 ortho total: 2.09186330139637\n",
      "time:  66.76228928565979\n",
      "Epoch:  103 Loss:  0.2725164133644104 Loss_std:  0.26346924478530886 Ortho_loss:  0 ortho total: 3.5340502113103858\n",
      "time:  68.17383480072021\n",
      "pairs 1.0 conv 20 ortho loss conv:  0.002760794758796692\n",
      "Epoch:  104 Loss:  0.26377522317886354 Loss_std:  0.25662330183029175 Ortho_loss:  0 ortho total: 2.793719327449799\n",
      "time:  67.76580238342285\n",
      "Epoch:  105 Loss:  0.2639088273143768 Loss_std:  0.25791462834358214 Ortho_loss:  0 ortho total: 2.341484075784685\n",
      "time:  72.82502818107605\n",
      "Epoch:  106 Loss:  0.2624812742996216 Loss_std:  0.2583362831687927 Ortho_loss:  0 ortho total: 1.619137185811996\n",
      "time:  70.52000951766968\n",
      "pairs 1.0 conv 20 ortho loss conv:  0.0035337209701538086\n",
      "Epoch:  107 Loss:  0.2683998028564453 Loss_std:  0.26145066555023194 Ortho_loss:  0 ortho total: 2.714506775140762\n",
      "time:  68.59062337875366\n",
      "Epoch:  108 Loss:  0.26822088433265684 Loss_std:  0.2632620287799835 Ortho_loss:  0 ortho total: 1.9370528817176798\n",
      "time:  68.94595003128052\n",
      "pairs 1.0 conv 20 ortho loss conv:  0.008519104123115542\n",
      "Epoch:  109 Loss:  0.26708767183303833 Loss_std:  0.2612001995277405 Ortho_loss:  0 ortho total: 2.299793821573259\n",
      "time:  68.99168825149536\n",
      "Epoch:  110 Loss:  0.2680851133346558 Loss_std:  0.25973967193603514 Ortho_loss:  0 ortho total: 3.259937942028045\n",
      "time:  71.64354085922241\n",
      "Epoch:  111 Loss:  0.26346063817977905 Loss_std:  0.25725121467590334 Ortho_loss:  0 ortho total: 2.425556164979936\n",
      "time:  68.50784134864807\n",
      "pairs 1.0 conv 20 ortho loss conv:  0.0030208498239517215\n",
      "Epoch:  112 Loss:  0.2715256863975525 Loss_std:  0.2634931767845154 Ortho_loss:  0 ortho total: 3.137699145078661\n",
      "time:  68.43889737129211\n",
      "Epoch:  113 Loss:  0.2668843177652359 Loss_std:  0.26094593122959137 Ortho_loss:  0 ortho total: 2.319682174921036\n",
      "time:  67.32198286056519\n",
      "Epoch:  114 Loss:  0.2650069750642777 Loss_std:  0.25869635941028596 Ortho_loss:  0 ortho total: 2.465084075927734\n",
      "time:  70.4234414100647\n",
      "pairs 1.0 conv 20 ortho loss conv:  0.006767073273658752\n",
      "Epoch:  115 Loss:  0.2663486216545105 Loss_std:  0.258394304523468 Ortho_loss:  0 ortho total: 3.1071551024913804\n",
      "time:  71.45646262168884\n",
      "Epoch:  116 Loss:  0.2641154914188385 Loss_std:  0.2582921479129791 Ortho_loss:  0 ortho total: 2.2747434914112072\n",
      "time:  71.2748236656189\n",
      "pairs 1.0 conv 20 ortho loss conv:  0.006392559409141541\n",
      "Epoch:  117 Loss:  0.2609421066570282 Loss_std:  0.25572114619255065 Ortho_loss:  0 ortho total: 2.039437648653983\n",
      "time:  72.14283061027527\n",
      "Epoch:  118 Loss:  0.26367404576301573 Loss_std:  0.25714160538673403 Ortho_loss:  0 ortho total: 2.5517346501350375\n",
      "time:  72.0800769329071\n",
      "Epoch:  119 Loss:  0.26060605663299563 Loss_std:  0.2552730512809753 Ortho_loss:  0 ortho total: 2.0832051634788535\n",
      "time:  69.75785756111145\n",
      "pairs 1.0 conv 20 ortho loss conv:  0.004052495956420899\n",
      "Epoch:  120 Loss:  0.25317187311172484 Loss_std:  0.24467658182144164 Ortho_loss:  0 ortho total: 3.3184732228517535\n",
      "time:  68.08834838867188\n",
      "0 0 0.649718785151856\n",
      "model:  0 5517  out of  10000\n",
      "0 1 0.7030995106035889\n",
      "model:  1 5962  out of  10000\n",
      "1 0 0.6657162026165716\n",
      "1 1 0.7040556967620731\n"
     ]
    }
   ],
   "source": [
    "df_lotos = train_ensemble(num_models, clip_flag=True, lotos_flag=True, seed_val=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   epoch        t0        t1     acc\n",
      "0     60  0.824739  0.821623  0.9095\n",
      "1     60  0.823898  0.823857  0.8987\n",
      "2     80  0.812996  0.835943  0.9203\n",
      "3     80  0.808296  0.825475  0.9162\n",
      "4    100  0.822866  0.843295  0.9219\n",
      "5    100  0.833988  0.825865  0.9194\n",
      "6    120  0.819305  0.840627  0.9231\n",
      "7    120  0.842709  0.817787  0.9209\n"
     ]
    }
   ],
   "source": [
    "print(df_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   epoch        t0        t1     acc\n",
      "0     60  0.773452  0.805003  0.8912\n",
      "1     60  0.859210  0.753593  0.8977\n",
      "2     80  0.725689  0.857650  0.9183\n",
      "3     80  0.837178  0.737552  0.9198\n",
      "4    100  0.676016  0.873330  0.9056\n",
      "5    100  0.859456  0.683820  0.9036\n",
      "6    120  0.663143  0.867396  0.9081\n",
      "7    120  0.884145  0.659411  0.9096\n"
     ]
    }
   ],
   "source": [
    "print(df_clip)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   epoch        t0        t1     acc\n",
      "0     60  0.719304  0.621961  0.8796\n",
      "1     60  0.515124  0.808196  0.8931\n",
      "2     80  0.708227  0.619055  0.9007\n",
      "3     80  0.545991  0.785051  0.9151\n",
      "4    100  0.660286  0.651832  0.8881\n",
      "5    100  0.643649  0.707518  0.8992\n",
      "6    120  0.649719  0.703100  0.8890\n",
      "7    120  0.665716  0.704056  0.9049\n"
     ]
    }
   ],
   "source": [
    "print(df_lotos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the average transferability rate, robustness, and acc for each epoch for each ensemble:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_results = summarize(df_orig, num_models)\n",
    "clip_results = summarize(df_clip, num_models)\n",
    "lotos_results = summarize(df_lotos, num_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Orig ensemble:\n",
      "    epoch     trans    robust      acc\n",
      "0     60  0.822761  0.175702  0.90410\n",
      "1     80  0.822119  0.180765  0.91825\n",
      "2    100  0.838642  0.175635  0.92065\n",
      "3    120  0.841668  0.181454  0.92200\n",
      "\n",
      "C=1 ensemble:\n",
      "    epoch     trans    robust      acc\n",
      "0     60  0.832106  0.236478  0.89445\n",
      "1     80  0.847414  0.268380  0.91905\n",
      "2    100  0.866393  0.320082  0.90460\n",
      "3    120  0.875771  0.338723  0.90885\n",
      "\n",
      "LOTOS ensemble\n",
      "    epoch     trans    robust      acc\n",
      "0     60  0.568543  0.236250  0.88635\n",
      "1     80  0.582523  0.253361  0.90790\n",
      "2    100  0.647741  0.316098  0.89365\n",
      "3    120  0.684408  0.323113  0.89695\n"
     ]
    }
   ],
   "source": [
    "print('\\nOrig ensemble:\\n', orig_results)\n",
    "print('\\nC=1 ensemble:\\n', clip_results)\n",
    "print('\\nLOTOS ensemble\\n', lotos_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making the plots similar to the ones in the paper and saving them to ```figs``` folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.clf()\n",
    "plt.plot(orig_results['epoch'], orig_results['trans'], label='Orig')\n",
    "plt.plot(clip_results['epoch'], clip_results['trans'], label='C=1')\n",
    "plt.plot(lotos_results['epoch'], lotos_results['trans'], label='LOTOS')\n",
    "plt.legend()\n",
    "plt.savefig('figs/transferability.png')\n",
    "plt.clf()\n",
    "\n",
    "plt.plot(orig_results['epoch'], orig_results['robust'], label='Orig')\n",
    "plt.plot(clip_results['epoch'], clip_results['robust'], label='C=1')\n",
    "plt.plot(lotos_results['epoch'], lotos_results['robust'], label='LOTOS')\n",
    "plt.legend()\n",
    "plt.savefig('figs/robustness.png')\n",
    "plt.clf()\n",
    "\n",
    "plt.plot(orig_results['epoch'], orig_results['acc'], label='Orig')\n",
    "plt.plot(clip_results['epoch'], clip_results['acc'], label='C=1')\n",
    "plt.plot(lotos_results['epoch'], lotos_results['acc'], label='LOTOS')\n",
    "plt.legend()\n",
    "plt.savefig('figs/accuracy.png')\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAGwCAYAAABB4NqyAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAU+FJREFUeJzt3XlcVPX+P/DXzDAMA7LJDiLgmgvuOpL2aHPvq1lWbrlTt3JL9F41U9NSblnGLU1/XTXrtlnmbbM0o8Vb4ZKioSKKG8gq67APzJzfHwMjAwPOwAwHmNfz8eDRzNnmc85F5nXP5/35HIkgCAKIiIiI7IhU7AYQERERtTQGICIiIrI7DEBERERkdxiAiIiIyO4wABEREZHdYQAiIiIiu8MARERERHbHQewGtEY6nQ7p6elwdXWFRCIRuzlERERkBkEQUFRUhMDAQEiljd/jYQAyIT09HcHBwWI3g4iIiJogNTUVnTp1anQbBiATXF1dAegvoJubm8itISIiInOo1WoEBwcbvscbwwBkQk23l5ubGwMQERFRG2NO+QqLoImIiMjuMAARERGR3WEAIiIiIrvDAERERER2hwGIiIiI7A4DEBEREdkdBiAiIiKyOwxAREREZHcYgIiIiMjuMAARERGR3WEAIiIiIrvDAERERER2hw9DJSIiopYhCECFGigrABxdABdv0ZrCAERERESWqSzTh5iyfKC8+r9G7xtaVwgIWv0x7lsN3LdKpBNgACIiIrJP2ip9ILE4xBQAVeXN+2wHJ0Bb2cwTaGYTRP10IiIiajpBACqKLAwxBfr3FermfbZEBig9ACcPQOmpf630rH5f+7WJdXJl8z7bChiAiIiIxFZZ3rQ7MWUFt7uUmkrhViu0eDQQWky8V7gCEknzPltEDEBERETWUNOlZHGIyW9+l5JMUR1SPC0LMU7ugMw+o4B9njUREZEpNV1KDQWVmu4jUwGn2V1KUjO6jxp43wq6lNoaBiAiImp/KsubEGLyrdOl5OhqeXeS0kO/n5TT87UUBiAiImqddNrbo5QsDTFVZc37bJmiaXdinNwBmbx5n00tggGIiIhsRxAATXETQkwhUFHYvM+WSPWBxNIQo/Rkl5IdYAAiIqI7q6po2p2Y8gJAV9W8z3bsUGd4tYd5IYZdStQIBiAiInsnCEBxNpB/Dci7BuRdrX59FVBnVI9Sam6XkmPT7sSwS4lshAGIiMge6LRA4c1a4aYm6FzXv64sMeMgEssLe2vey5Vtes4Yan8YgIiI2ovKcqDgRp27ONWvC1IAXSOPHpBIAbdOQMdQoGMXwDMM6BgGuAffnl9G4cYuJWo3GICIiNqScvXt7qm8a7VCzjVAnQZAaHhfmSPgGXo73NQOOh6dAQdFS50FkegYgIiIWhNBAEpu1Qo3V41fl+Y2vr+jq/4ujmd1wKkddNwCAamsRU6DqLVjACIiamk6rf5uTb2uquqgoylufH9n79vhpnbQ8QwDXLxZa0NkBgYgIiJbqKrQ193U3MGpHXQKbgBaTSM7SwD3TvruqrpBxzMUcHJroZMgar8YgIiImqqiqIGuqmv6EVeN1eNI5YBniHEdTs1rzxDW4xDZGAMQEVFDBEFfc1N3bpyaoFNyq/H95S7Vd3BC6wcdtyDW4xCJiAGIiOybTqevx6k3CWD1j6ao8f2dverX4dS8dvFhPQ5RK8UARETtX5VGX49T+w5OTdDJvwFoKxrf361TdbgJrRN0wvQzFRNRm8MARETtQ0Xx7Ts3dbuqCm8Cgq7hfaUOgEdInblxqoOORwggd2q58yCiFsEARERtgyAApXmm58bJuwaUZDe+v9z59iiqupMAunUCZPxzSGRP+C+eiFoPnQ4oyjDxvKrq1xXqxvdXdqxfh1MTdDr4sh6HiAwYgIioZWkrq+fHMfW8qhtAVXnj+7sG3h5ZVbf4WOnREmdARO2A6AFo+/bt2LJlCzIzM9G/f3+8/fbbGDZsWIPbx8TEYMeOHUhJSYG3tzcee+wxREdHw8lJ30f/0ksvYcOGDUb79OzZExcvXrTpeRBRLZqS6qeMm+iqKkw1ox6ns+mRVZ4h+qeKExE1k6gBaN++fYiKisLOnTuhUqkQExODsWPHIikpCb6+vvW2//jjj7Fq1Srs2bMHd999Ny5duoS5c+dCIpFg69athu369OmDH3/80fDewUH0nEfU/pTmNfy8quKsxvd1UNbqngo17qpyD2Y9DhHZnKh/ZbZu3YqnnnoK8+bNAwDs3LkTBw8exJ49e7Bq1ap62//xxx8YMWIEZsyYAQAIDQ3F9OnTcfz4caPtHBwc4O/vb/sTIGrPdDqgONN0V1X+NaC8sPH9lZ6mnzresQvQwY/1OEQkKtECkEajwalTp7B69WrDMqlUilGjRiEuLs7kPnfffTc+/PBDnDhxAsOGDcPVq1fx3XffYdasWUbbXb58GYGBgXByckJERASio6PRuXPnBttSUVGBiorb84Co1XcotCRqL7SV+i4pw9w414yHkt+xHiegVldVqHG3ldKzRU6BiKgpRAtAOTk50Gq18PPzM1ru5+fXYL3OjBkzkJOTg5EjR0IQBFRVVeGZZ57BCy+8YNhGpVJh79696NmzJzIyMrBhwwbcc889OHfuHFxdXU0eNzo6ul7dEFG7oSnV1+OY6qoqSAUEbcP7SmT6ehxTTx33DAUcnVvqLIiIrKpNdbT/8ssv2Lx5M9555x2oVCokJydj6dKlePnll7F27VoAwPjx4w3b9+vXDyqVCiEhIfjss8+wYMECk8ddvXo1oqKiDO/VajWCg4NtezJE1iIIQFn+7aLj2o9xyL+mH1beGAdlnTqcWq/dgwGZvAVOgoioZYkWgLy9vSGTyZCVZVwsmZWV1WD9ztq1azFr1ixERkYCAMLDw1FSUoKnn34aa9asgVQqrbePh4cHevTogeTk5AbbolAooFDwycvUCtWEG3UaoE7Xz2isTq9+nwYUVi+vKmv8OE7upp863jEM6OAPmPi3Q0TUnokWgBwdHTF48GDExsZi8uTJAACdTofY2FgsWrTI5D6lpaX1Qo5Mpn+asiAIJvcpLi7GlStX6tUJEYnOEG5MBBp1TdBJBypLzTteB7/6j3Go6a5y7mjbcyEiamNE7QKLiorCnDlzMGTIEAwbNgwxMTEoKSkxjAqbPXs2goKCEB0dDQCYOHEitm7dioEDBxq6wNauXYuJEycagtCKFSswceJEhISEID09HevXr4dMJsP06dNFO0+yQ4IAlBfUDzSFabfDjiXhxtkbcAsE3Dvp/+sWpP9xD9K/dw3k86qIiCwgagCaOnUqbt26hXXr1iEzMxMDBgzAoUOHDIXRKSkpRnd8XnzxRUgkErz44otIS0uDj48PJk6ciE2bNhm2uXnzJqZPn47c3Fz4+Phg5MiROHbsGHx8fFr8/KidEgT9EHDDHZs0E11U6UBliXnHc/aqH2jcqoOOexDDDRGRDUiEhvqO7JharYa7uzsKCwvh5uYmdnOoJRnCTSPdUoVpFoabOoGmJuy4Bep/OLMxEZFVWPL93aZGgRE1iyDoH6Z5p24pTbF5x1N2rHPXpvZdnCCGGyKiVowBiNqPmjs3RoGm9h2cNAvCjWeduza17+J00k8AyDlwiKgN0OoEVGp10Gh1qNLqX+t/GnldpUOVTgdNnddVd9q3SkClrv4xavar/Xr6sM6YNyJMtOvCAERtQ7m68S4pdTqgKTLvWEpP424oo26p6mUMN0RUhyAIqKoOE7e/6I1fV2kFaLS66i9/49eVWh00pl5X6VBpOG79/Ro7Ru3wYfjsOq9ba6FLdlHFnTeyIQYgEl+5uvEuqcI088ONk0fDxcSGcONi09MhojvT6YzvFNS7a1Cl/2KveV1VHTBqvzYEj6rqfXXVy7Q6w2tT+5k8hokgYypstAdSCSCXSeEok8JBJoFcJq3+0b92kEnhaHgtqbetefsZv5bLJNX73d4+2FPc/6PJAES2VVHUyEip6vcVZj57zcm94WLimuHhDDdETSYIAvJKNEgvKEdaQSlu5pchv1SDSq0ATZVxMKisuXPRyOsqXa39dMZBR6trH2FCLpPAQVr9Be8g1b92kEAurQ4HDvr1jrVey2VSODbwWl4rWDhUhwa5TFIdKIyPITcRQoxeO0ghlxoHGblMCpmUDyIGGICoOSqK79wtVXGHJ4bXcHI3HWhqL1N0sO35ELVzVVodsooqkJZfhrSC0ur/liGtoBxp+aVILyhHWWUjz4azIYmpuxJSif5LXCaFg1QfMEy9ljtU71ezvbR+AJA7mD5GTXjRb1vntUNNOxoKMhJIJAwTbRUDEJlWUXznbilzw43Cvf5dG6MuqgBAYfpBtURkvjKNtjrQlBlCTnpBuSHoZKrLzbrz4uOqQJCHEkGeSvh0UFSHhoa7PPR3PYxfN3R3wiiEGO5w8K4EtTwGIHukKblDt1SafkSVORRuDRQT17qLw3BD1GyCIKCgtBJpBWW4WR1o0g1BR/+TV6K543HkMgkC3JWGgBPkYfw6wMMJCgdZC5wRkbgYgNobTUnjD81U37Qw3AQ23i3lxIkiiaxBqxOQpS6vdfemzOh1ekEZSjV37p7qoHAwCjSBtV53qr6jI+XdFiIGoDZFU3qHmps0/fOnzOHo2sAEfrVGTjHcEFlNeaW2XqBJyy/Dzer/mts95d1BgSBPJTp5KBHo4VQddpwNocfNyYF1KURmYABqLTSld6i5uWlBuOnQ8Bw3Ne8ZboisRhAEFJZVNtg1lV5QhpziO3dPOUglCKgONYEe+pCjv3vjjEAPJwR6KOEkZ/cUkTUwALWkW0lA2ml9yKk9O7E6DSjLN+8YcpdGiomrA4/CTT+kgoisQqsTkF1U3mDXVFp+GUrM6J5ycZQhyLO6W6pO11SghxK+rk4sBiZqIQxALen8f4Ffohtebwg3jTw808md4YbIysortUgvKDPMf1O7ayq9sAwZBeWoMqt7yvF2uKlTh9PJUwl3pZzdU0StBANQS/LtDYTdW7+Y2NAtxXBDZG2CIEBdVoWbhiHhpbfv4lQPEc8pvvOU/DKpBP5uTob6G1NFxuyeImo7GIBaUu9J+h8ishqdTkB2UUWj898UV1Td8ThKuez2sHATw8P93Ng9RdSeMAARUatWUaVFRsHt4eE36xQZZxSWmfWMpo4ujkahpqarqlN1wPFwZvcUkT1hACIiUanLK/VhplZR8c1aAeeWGU+MNnRPGcKNE4I8nI3u5Cgd2T1FRLcxABGRzeh0AnKKK4wCjdEQ8fwyFJnRPeUklxrPd+PhZBgeHuSphJ+rAg4yaQucERG1FwxARNRkmiodMgpNd02lFehHT2m0ujsex9NZblxUbOia0s9/09HFkd1TRGRVDEBE1KCi8soGH82Qll+GW8UVEO5QfiOVwDB6qu78NzWBx0XBP0VE1LL4V4fITgmCgFvFFSa7pm7m69+ry+/cPaVwkBqPmqpTZOzv7gQ5u6eIqJVhAGpBBaUa5JVoIJFIIJUAEkgM0/5IJIBUon9fs1wCQCKp87p6W1PLa/avOZ4E1Z9TZz+yD5oqHTILy2vNf6MfHp5mmPCvDJqqO3dPeTjLEehef9bimqDjxe4pImqDGIBa0EfHU7DlcJLYzTAdqGpCV50AJq1+UTuMSWvthzrb1j42AEil5gU6afX2xmHt9mehzra12w0JjAKl8fnU3haG8AmjNhmHz5rzrXs+9dtf53PqLK8Jn6i37PbxUHe5yWtV6xpLjY8nqXXuuSUaozs5WUXld+yekkgAP1cno/lvaj+DKtBDiQ7sniKidoh/2VqQwkEKVycHQAAEADpBgCAAAmr+q++WMHoN3PFLzFI1xzc+sJU/hFoFRwdpg11TnTzZPUVE9ksiCNb+em371Go13N3dUVhYCDe31vHU9LrBSFcrOOnXVwcqGAcnU4FKV73AsA2qjycYH89oOWryUs2yWsGt+rNr72fcHv1++mV12lfrGLWD4O02Gn+GyeOZDJC1j2tieZ1rhlrHvh1M9fsBdZfVPr6Zx6u1H+p9Rp3j1buOt8/X+H+X28cTALg5ORgNDQ/y0HdPSTl7MRHZCUu+v3kHqI2o6Q6pfidmU4iIiNo83vsmIiIiu8MARERERHaHAYiIiIjsDgMQERER2R0GICIiIrI7DEBERERkdxiAiIiIyO4wABEREZHdYQAiIiIiu8MARERERHaHAYiIiIjsDgMQERER2R0GICIiIrI7DEBERERkdxiAiIiIyO4wABEREZHdYQAiIiIiu8MARERERHZH9AC0fft2hIaGwsnJCSqVCidOnGh0+5iYGPTs2RNKpRLBwcFYtmwZysvLm3VMIiIisi+iBqB9+/YhKioK69evx+nTp9G/f3+MHTsW2dnZJrf/+OOPsWrVKqxfvx6JiYnYvXs39u3bhxdeeKHJxyQiIiL7IxEEQRDrw1UqFYYOHYpt27YBAHQ6HYKDg7F48WKsWrWq3vaLFi1CYmIiYmNjDcuWL1+O48eP47fffmvSMU1Rq9Vwd3dHYWEh3NzcmnuaRERE1AIs+f4W7Q6QRqPBqVOnMGrUqNuNkUoxatQoxMXFmdzn7rvvxqlTpwxdWlevXsV3332HCRMmNPmYAFBRUQG1Wm30Q0RERO2Xg1gfnJOTA61WCz8/P6Plfn5+uHjxosl9ZsyYgZycHIwcORKCIKCqqgrPPPOMoQusKccEgOjoaGzYsKGZZ0RERERthehF0Jb45ZdfsHnzZrzzzjs4ffo0Dhw4gIMHD+Lll19u1nFXr16NwsJCw09qaqqVWkxEREStkWh3gLy9vSGTyZCVlWW0PCsrC/7+/ib3Wbt2LWbNmoXIyEgAQHh4OEpKSvD0009jzZo1TTomACgUCigUimaeEREREbUVot0BcnR0xODBg40KmnU6HWJjYxEREWFyn9LSUkilxk2WyWQAAEEQmnRMIiIisj+i3QECgKioKMyZMwdDhgzBsGHDEBMTg5KSEsybNw8AMHv2bAQFBSE6OhoAMHHiRGzduhUDBw6ESqVCcnIy1q5di4kTJxqC0J2OSURERCRqAJo6dSpu3bqFdevWITMzEwMGDMChQ4cMRcwpKSlGd3xefPFFSCQSvPjii0hLS4OPjw8mTpyITZs2mX1MIiIiIlHnAWqtOA8QERFR29Mm5gEiIiIiEgsDEBEREdkdBiAiIiKyOwxAREREZHcYgIiIiMjuMAARERGR3WEAIiIiIrvDAERERER2hwGIiIiI7A4DEBEREdkdBiAiIiKyOwxAREREZHcYgIiIiMjuMAARERGR3WEAIiIiIrvDAERERER2hwGIiIiI7A4DEBEREdkdBiAiIiKyOwxAREREZHcYgIiIiMjuMAARERGR3WEAIiIiIrvDAERERER2hwGIiIiI7A4DEBEREdkdBiAiIiKyOwxAREREZHcYgIiIiMjuMAARERGR3bE4AP3888+2aAcRERFRi7E4AI0bNw5du3bFK6+8gtTUVFu0iYiIiMimLA5AaWlpWLRoEfbv348uXbpg7Nix+Oyzz6DRaGzRPiIiIiKrszgAeXt7Y9myZThz5gyOHz+OHj164LnnnkNgYCCWLFmCs2fP2qKdRERERFbTrCLoQYMGYfXq1Vi0aBGKi4uxZ88eDB48GPfccw/Onz9vrTYSERERWVWTAlBlZSX279+PCRMmICQkBIcPH8a2bduQlZWF5ORkhISE4PHHH7d2W4mIiIisQiIIgmDJDosXL8Ynn3wCQRAwa9YsREZGom/fvkbbZGZmIjAwEDqdzqqNbSlqtRru7u4oLCyEm5ub2M0hIiIiM1jy/e1g6cEvXLiAt99+G48++igUCoXJbby9vTlcnoiIiFoti7vA1q9fj8cff7xe+KmqqsLRo0cBAA4ODrj33nut00IiIiIiK7M4AN1///3Iy8urt7ywsBD333+/VRpFREREZEsWByBBECCRSOotz83NhYuLi1UaRURERGRLZtcAPfroowAAiUSCuXPnGnWBabVa/PXXX7j77rut30IiIiIiKzM7ALm7uwPQ3wFydXWFUqk0rHN0dMTw4cPx1FNPWb+FRERERFZmdgB67733AAChoaFYsWIFu7uIiIiozWrSKDBrh5/t27cjNDQUTk5OUKlUOHHiRIPb3nfffZBIJPV+HnroIcM2c+fOrbd+3LhxVm0zERERtV1m3QEaNGgQYmNj4enpiYEDB5osgq5x+vRpixqwb98+REVFYefOnVCpVIiJicHYsWORlJQEX1/fetsfOHDA6MGrubm56N+/f72Zp8eNG2e4awWgwTmLiIiIyP6YFYAefvhhQ4CYPHmyVRuwdetWPPXUU5g3bx4AYOfOnTh48CD27NmDVatW1du+Y8eORu8//fRTODs71wtACoUC/v7+ZrWhoqICFRUVhvdqtdrS0yAiIqI2xKwAtH79epOvm0uj0eDUqVNYvXq1YZlUKsWoUaMQFxdn1jF2796NadOm1euW++WXX+Dr6wtPT0888MADeOWVV+Dl5WXyGNHR0diwYUPTT4SIiIjalGY9Db65cnJyoNVq4efnZ7Tcz88PmZmZd9z/xIkTOHfuHCIjI42Wjxs3Dh988AFiY2Px6quv4tdff8X48eOh1WpNHmf16tUoLCw0/KSmpjb9pIiIiKjVM+sOkKenZ6N1P7WZmiXaVnbv3o3w8HAMGzbMaPm0adMMr8PDw9GvXz907doVv/zyCx588MF6x1EoFKwRIiIisiNmBaCYmBibfLi3tzdkMhmysrKMlmdlZd2xfqekpASffvopNm7ceMfP6dKlC7y9vZGcnGwyABEREZF9MSsAzZkzxyYf7ujoiMGDByM2NtZQXK3T6RAbG4tFixY1uu/nn3+OiooKPPnkk3f8nJs3byI3NxcBAQHWaDYRERG1cWYFILVaDTc3N8PrxtRsZ66oqCjMmTMHQ4YMwbBhwxATE4OSkhLDqLDZs2cjKCgI0dHRRvvt3r0bkydPrlfYXFxcjA0bNmDKlCnw9/fHlStX8I9//APdunXD2LFjLWobERERtU9m1wBlZGTA19cXHh4eJuuBah6S2lChcUOmTp2KW7duYd26dcjMzMSAAQNw6NAhQ2F0SkoKpFLjWu2kpCT89ttv+OGHH+odTyaT4a+//sL777+PgoICBAYGYsyYMXj55ZdZ50NEREQAAIkgCMKdNvr1118xYsQIODg44Ndff21023vvvddqjROLWq2Gu7s7CgsLLb6jRUREROKw5PvbrABkbxiAiIiI2h5Lvr/Nfhhqbfn5+di9ezcSExMBAL1798a8efPqzdJMRERE1BpZPBHi0aNHERoairfeegv5+fnIz8/HW2+9hbCwMBw9etQWbSQiIiKyKou7wMLDwxEREYEdO3ZAJpMBALRaLZ577jn88ccfSEhIsElDWxK7wIiIiNoeS76/Lb4DlJycjOXLlxvCD6AfeRUVFYXk5GTLW0tERETUwiwOQIMGDTLU/tSWmJiI/v37W6VRRERERLZkVhH0X3/9ZXi9ZMkSLF26FMnJyRg+fDgA4NixY9i+fTv++c9/2qaVRERERFZkVg2QVCqFRCLBnTZtykSIrRFrgIiIiNoeqw+Dv3btmlUaRkRERNQamBWAQkJCbN0OIiIiohbTpIkQAeDChQtISUmBRqMxWj5p0qRmN4qIiIjIliwOQFevXsUjjzyChIQEo7qgmgektocaICIiImrfLB4Gv3TpUoSFhSE7OxvOzs44f/48jh49iiFDhuCXX36xQROJiIiIrMviO0BxcXH46aef4O3tDalUCqlUipEjRyI6OhpLlixBfHy8LdpJREREZDUW3wHSarVwdXUFAHh7eyM9PR2AvlA6KSnJuq0jIiIisgGL7wD17dsXZ8+eRVhYGFQqFV577TU4Ojri3XffRZcuXWzRRiIiIiKrsjgAvfjiiygpKQEAbNy4Ef/3f/+He+65B15eXti3b5/VG0hERERkbRY/Dd6UvLw8eHp6GkaCtXWcCZqIiKjtsdnT4CsrK+Hg4IBz584ZLe/YsWO7CT9ERETU/lkUgORyOTp37sy5foiIiKhNs3gU2Jo1a/DCCy8gLy/PFu0hIiIisjmLi6C3bduG5ORkBAYGIiQkBC4uLkbrT58+bbXGEREREdmCxQFo8uTJNmgGERERUcuxyiiw9oajwIiIiNoem40Cq1FQUIBdu3Zh9erVhlqg06dPIy0trSmHIyIiImpRFneB/fXXXxg1ahTc3d1x/fp1PPXUU+jYsSMOHDiAlJQUfPDBB7ZoJxEREZHVWHwHKCoqCnPnzsXly5fh5ORkWD5hwgQcPXrUqo0jIiIisgWLA9DJkyfxt7/9rd7yoKAgZGZmWqVRRERERLZkcQBSKBRQq9X1ll+6dAk+Pj5WaRQRERGRLVkcgCZNmoSNGzeisrISACCRSJCSkoKVK1diypQpVm8gERERkbVZHIDeeOMNFBcXw9fXF2VlZbj33nvRrVs3uLq6YtOmTbZoIxEREZFVWTwKzN3dHUeOHMHvv/+Os2fPori4GIMGDcKoUaNs0T4iIiIiqzMrAHXs2BGXLl2Ct7c35s+fj3/9618YMWIERowYYev2EREREVmdWV1gGo3GUPj8/vvvo7y83KaNIiIiIrIls+4ARUREYPLkyRg8eDAEQcCSJUugVCpNbrtnzx6rNpCIiIjI2swKQB9++CHefPNNXLlyBRKJBIWFhbwLRERERG2WxQ9DDQsLw59//gkvLy9btUl0fBgqERFR22PJ97fFo8CuXbtWb1lBQQE8PDwsPRQRERGRKCyeB+jVV1/Fvn37DO+feOIJdOzYEUFBQTh79qxVG0dERERkCxYHoJ07dyI4OBgAcOTIERw5cgSHDh3C+PHj8fe//93qDSQiIiKyNou7wDIzMw0B6Ntvv8UTTzyBMWPGIDQ0FCqVyuoNJCIiIrI2i+8AeXp6IjU1FQBw6NAhwwzQgiBAq9Vat3VERERENmDxHaBHH30UM2bMQPfu3ZGbm4vx48cDAOLj49GtWzerN5CIiIjI2iwOQG+++SZCQ0ORmpqK1157DR06dAAAZGRk4LnnnrN6A4mIiIiszeIuMLlcjhUrVuBf//oXBg4caFi+bNkyREZGNqkR27dvR2hoKJycnKBSqXDixIkGt73vvvsgkUjq/Tz00EOGbQRBwLp16xAQEAClUolRo0bh8uXLTWobERERtT8W3wECgMuXL+Pnn39GdnY2dDqd0bp169ZZdKx9+/YhKioKO3fuhEqlQkxMDMaOHYukpCT4+vrW2/7AgQPQaDSG97m5uejfvz8ef/xxw7LXXnsNb731Ft5//32EhYVh7dq1GDt2LC5cuAAnJycLz5aIiIjaG4tngv73v/+NZ599Ft7e3vD394dEIrl9MIkEp0+ftqgBKpUKQ4cOxbZt2wAAOp0OwcHBWLx4MVatWnXH/WNiYrBu3TpkZGTAxcUFgiAgMDAQy5cvx4oVKwAAhYWF8PPzw969ezFt2rR6x6ioqEBFRYXhvVqtRnBwMGeCJiIiakMsmQna4i6wV155BZs2bUJmZibOnDmD+Ph4w4+l4Uej0eDUqVOGkWQAIJVKMWrUKMTFxZl1jN27d2PatGlwcXEBoJ+pOjMz0+iY7u7uUKlUDR4zOjoa7u7uhp+aYf5ERETUPlkcgPLz8426m5ojJycHWq0Wfn5+Rsv9/PyQmZl5x/1PnDiBc+fOGdUe1exnyTFXr16NwsJCw0/NMH8iIiJqnywOQI8//jh++OEHW7TFYrt370Z4eDiGDRvWrOMoFAq4ubkZ/RAREVH7ZXERdLdu3bB27VocO3YM4eHhkMvlRuuXLFli9rG8vb0hk8mQlZVltDwrKwv+/v6N7ltSUoJPP/0UGzduNFpes19WVhYCAgKMjjlgwACz20ZERETtl8UB6N1330WHDh3w66+/4tdffzVaJ5FILApAjo6OGDx4MGJjYzF58mQA+iLo2NhYLFq0qNF9P//8c1RUVODJJ580Wh4WFgZ/f3/ExsYaAo9arcbx48fx7LPPmt02IiIiar8sDkDXrl2zagOioqIwZ84cDBkyBMOGDUNMTAxKSkowb948AMDs2bMRFBSE6Ohoo/12796NyZMnw8vLy2i5RCLB888/j1deeQXdu3c3DIMPDAw0hCwiIiKyb02aB8iapk6dilu3bmHdunXIzMzEgAEDcOjQIUMRc0pKCqRS41KlpKQk/Pbbbw3WIv3jH/9ASUkJnn76aRQUFGDkyJE4dOgQ5wAiIiIiAE2YBwgAbt68ia+//hopKSlGkxICwNatW63WOLFYMo8AERERtQ6WfH9bfAcoNjYWkyZNQpcuXXDx4kX07dsX169fhyAIGDRoUJMbTURERNRSLB4Gv3r1aqxYsQIJCQlwcnLCF198gdTUVNx7771Wmx+IiIiIyJYsDkCJiYmYPXs2AMDBwQFlZWXo0KEDNm7ciFdffdXqDSQiIiKyNosDkIuLi6HuJyAgAFeuXDGsy8nJsV7LiIiIiGzE4hqg4cOH47fffkOvXr0wYcIELF++HAkJCThw4ACGDx9uizYSERERWZXFAWjr1q0oLi4GAGzYsAHFxcXYt28funfv3i5GgBEREVH7Z1EA0mq1uHnzJvr16wdA3x22c+dOmzSMiIiIyFYsqgGSyWQYM2YM8vPzbdUeIiIiaucEQYBWpxW1DRYXQfft2xdXr161RVuIiIioncoty8V3V7/Dut/XYcwXY/Dt1W9FbY/FNUCvvPIKVqxYgZdffhmDBw+Gi4uL0XrOnExERESllaU4nX0ax9KP4VjGMSTlJxmtP55xHA93e1ik1lnwKIyNGzdi+fLlcHV1vb2zRGJ4LQgCJBIJtFpxb2lZAx+FQUREZBmtTovzuedxLEMfeM5kn0GlrtJom56ePTE8YDgiAiMw0HcgnOXOVm2DJd/fZgcgmUyGjIwMJCYmNrrdvffea35LWykGICIiosYJgoCUohTEpcfhWMYxnMg8gSJNkdE2/i7+iAiIwPCA4VAFqOCl9LJpm2zyLLCanNQeAg4RERFZLrcsFycyTxhCT0ZJhtF6V7krhgUMw/CA4RgeMBwhbiFGvUWtiUU1QK31JIiIiMj6yqrKcDrrtCHw1K3jcZA6YKDvQEPg6e3VGw5Si8uLRWFRK3v06HHHEJSXl9esBhEREZE4tDotLuRewLGMY4jLiGu0jmd44HAM8h1k9TqelmJRANqwYQPc3d1t1RYiIiJqQTV1PDUjtY5nHm+0jmdYwDB4K71Faq11WRSApk2bBl9fX1u1hYiIiGwsrzwPxzOO6+/ypMeZrOMZ6j8UEYERrb6OpznMDkDt8eSJiIjau5o6nprh6RfzLhqtd5A6YIDPAMPw9LZUx9McFo8CIyIiotardh3PsYxjiM+Or1fH08OzhyHwtOU6nuYwOwDpdDpbtoOIiIiaQBAEpBalGkZqmarj8XP2M3RpqQJU7aaOpzna/z0uIiKidiavPA8nMk4gLiMOx9KPIb0k3Wh9B3kHDPMfhuGBwxERENFu63iagwGIiIiolSurKkN8VrxheHpjdTzDA4ejj1cfu6jjaQ5eHSIiolZGq9MiMS/RMFKrsTqe4QHDMdhvsF3W8TQHAxAREZHIaup4agqXj2cch1qjNtqGdTzWxQBEREQkgpo6npq7PKbqeGrPxxPqFso6HitiACIiImoB5VXlRvPxJOYlGq13kDqgv09//azLrOOxOV5ZIiIiG9DqtLiYd9EwUis+Ox4ancZom+6e3fXz8QREsI6nhTEAERERWYEgCLhZdFMfeBqo4/F19jXc4RkeMJx1PCJiACIiImqi/PJ8HM88bniYaFpxmtH6mjqemlmXWcfTejAAERERmam8qhyns6vreNIbruOpGZ7e17sv63haKf6vQkRE1ACjOp6MY4jPariOZ3jAcAzxG8I6njaCAYiIiKiWVHWqIfCcyDyBwopCo/Ws42kfGICIiMiuWVLHMzxwOMLcwljH0w4wABERkV0prypHfHa8YXj6xbyLECAY1jtIHNDPp59hAkLW8bRP/F+UiIjaNa1Oi4v5FxGX3nAdTzePboaRWqzjsQ8MQERE1O7UPFcrLj3OdB2P0hfDA/WBR+Wvgo+zj0gtJbEwABERUZtXUF6gr+OpDj1163hc5C5G8/GwjocYgIiIqM2pqeOpCTwN1fEMD9Q/ZoJ1PFQXfxuIiKjV0wk6JOYlGkZqxWfHo0JbYbRN7TqewX6D4SJ3Eam11BYwABERUatUU8dzLP0Yjmceb7COp2YSQtbxkCUYgIiIqFWoXcdzLP0YbhbfNFpvVMcTEIEwd9bxUNMxABERkSgqtBX6+Xiqh6cn5iY2WsfTx7sP5FK5iC2m9oQBiIiIWoRO0OFi3kVD4TLreEhMogeg7du3Y8uWLcjMzET//v3x9ttvY9iwYQ1uX1BQgDVr1uDAgQPIy8tDSEgIYmJiMGHCBADASy+9hA0bNhjt07NnT1y8eNGm50FERPXdLLppNB9PQUWB0XrW8ZBYRA1A+/btQ1RUFHbu3AmVSoWYmBiMHTsWSUlJ8PX1rbe9RqPB6NGj4evri/379yMoKAg3btyAh4eH0XZ9+vTBjz/+aHjv4CB6ziMisguFFYU4nnF7Ph6TdTx+Qw3dWqzjIbGImgy2bt2Kp556CvPmzQMA7Ny5EwcPHsSePXuwatWqetvv2bMHeXl5+OOPPyCX6/uBQ0ND623n4OAAf39/m7adiIhu1/HUDE+/kHvBdB1P9YNE+3r3ZR0PtQqiBSCNRoNTp05h9erVhmVSqRSjRo1CXFycyX2+/vprREREYOHChfjqq6/g4+ODGTNmYOXKlZDJZIbtLl++jMDAQDg5OSEiIgLR0dHo3Llzg22pqKhARcXtfmi1Wm2FMyQian9q1/EcSz+G09mnG6zjGR4wHEP8h7COh1ol0QJQTk4OtFot/Pz8jJb7+fk1WK9z9epV/PTTT5g5cya+++47JCcn47nnnkNlZSXWr18PAFCpVNi7dy969uyJjIwMbNiwAffccw/OnTsHV1dXk8eNjo6uVzdERER6acVphpFaxzOO16vj8VH6GJ6crgpQwde5fgkDUWvTpopjdDodfH198e6770Imk2Hw4MFIS0vDli1bDAFo/Pjxhu379esHlUqFkJAQfPbZZ1iwYIHJ465evRpRUVGG92q1GsHBwbY9GSKiViy3LBcfJX6EQ9cPIbUo1Wids4MzhvkPMxQvd3HvwjoeanNEC0De3t6QyWTIysoyWp6VldVg/U5AQADkcrlRd1evXr2QmZkJjUYDR0fHevt4eHigR48eSE5ObrAtCoUCCoWiiWdCRNR+pBenY+/5vThw+YCha0smkaGfTz9EBESwjofaDdECkKOjIwYPHozY2FhMnjwZgP4OT2xsLBYtWmRynxEjRuDjjz+GTqeDVCoFAFy6dAkBAQEmww8AFBcX48qVK5g1a5ZNzoOIqD24WnAVu8/txndXv0OVUAUA6OfdD7P7zMaIwBHo4NhB5BYSWZeoXWBRUVGYM2cOhgwZgmHDhiEmJgYlJSWGUWGzZ89GUFAQoqOjAQDPPvsstm3bhqVLl2Lx4sW4fPkyNm/ejCVLlhiOuWLFCkycOBEhISFIT0/H+vXrIZPJMH36dFHOkYioNTuXcw67Enbhp5SfDKO3hgcMx1PhT2Go/1B2bVG7JWoAmjp1Km7duoV169YhMzMTAwYMwKFDhwyF0SkpKYY7PQAQHByMw4cPY9myZejXrx+CgoKwdOlSrFy50rDNzZs3MX36dOTm5sLHxwcjR47EsWPH4OPDybWIiABAEASczDyJfyf8G8cyjhmWP9j5QUSGR6Kvd18RW0fUMiSCIAh33sy+qNVquLu7o7CwEG5ubmI3h4jIKnSCDr+m/opdCbvwV85fAPT1PQ91eQjz+85HV4+uIreQqHks+f5uU6PAiIjIclW6Khy6fgi7E3YjuUA/IEQhU+CRbo9gbt+5COoQJHILiVoeAxARUTtVoa3AV8lfYc+5PUgrTgMAdJB3wNSeU/Fk7yfhrfQWuYVE4mEAIiJqZ0oqS/BZ0mf44MIHyCnLAQB0dOqIJ3s9ial3TYWbI7v2iRiAiIjaifzyfHyU+BE+vvgxijRFAAB/F3/M6zMPj3R/BEoHpcgtJGo9GICIiNq4zJJMvH/+fXxx+QuUVZUBAMLcwzC/73w8FPYQ5DJOWkhUFwMQEVEbdb3wOt47/x6+vvI1qnT6yQt7e/XGU+FP4YHOD0Aqkd7hCET2iwGIiKiNScxNxK6EXThy44hh8sKh/kMR2TcSEYERnLyQyAwMQEREbcSprFP4d8K/8Xva74Zl93W6DwvCF2CA7wDxGkbUBjEAERG1YoIg4H9p/8OuhF2Iz44HAEglUowLHYcF4QvQw7OHyC0kapsYgIiIWiGtTosjN45gV8IuJOUnAQDkUjkmd5uMeX3mIdgtWOQWErVtDEBERK2IRqvBN1e+wZ5ze5BSlAIAcHZwxhM9n8Cs3rPg6+wrcguJ2gcGICKiVqC0shT7L+3H++ffR3ZZNgDAXeGOmb1mYsZdM+CucBe5hUTtCwMQEZGICisK8fHFj/FR4kcorCgEAPg6+2JO7zl4rMdjcJY7i9xCovaJAYiISAS3Sm/hgwsf4LOkz1BaVQoA6OzaGfP7zsfErhPhKHMUuYVE7RsDEBFRC0pVp2LP+T34KvkrVOoqAQA9PXsiMjwSo0NGQyaVidxCIvvAAERE1AIu5V/CroRdOHz9MHSCDgAwyHcQFoQvwD1B93DyQqIWxgBERGRDZ7LPYHfCbvxy8xfDspFBIxEZHonBfoPFaxiRnWMAIiKyMkEQEJceh13nduFk5kkAgAQSjAkdgwV9F6CXVy+RW0hEDEBERFaiE3SITYnFroRduJB7AQDgIHXApK6TMK/PPIS6h4rbQCIyYAAiImqmSl0lDl49iD3n9uBa4TUAgNJBiSndp2BOnznwd/EXuYVEVBcDEBFRE5VVleHA5QPYe34vMksyAQCujq6YcdcMzOw1E55OniK3kIgawgBERGQhtUaNfRf34cPED5FXngcA8HLywpw+c/B4j8fRwbGDyC0kojthACIiMlNOWQ4+vPAh9iXtQ3FlMQAgqEMQ5vedj4e7PQyFTCFyC4nIXAxARER3kFachr3n9uK/yf9FhbYCANDNoxsWhC/AuNBxcJDyTylRW8N/tUREDbhScAV7zu3BwasHoRW0AIB+3v0QGR6Je4PvhVQiFbmFJDatVovKykqxm2E35HI5ZDLrzJbOAEREVMe5nHPYlbALsSmxhmURARGIDI/EUP+hnLWZIAgCMjMzUVBQIHZT7I6Hhwf8/f2b/e+QAYiICPovtBOZJ7ArYReOZRwzLB/VeRQWhC9AX+++IraOWpua8OPr6wtnZ2eG4hYgCAJKS0uRnZ0NAAgICGjW8RiAiMiu6QQdfkn9BbsTduOvnL8AADKJDA91eQgL+i5AF48u4jaQWh2tVmsIP15eXmI3x64olUoAQHZ2Nnx9fZvVHcYARER2qUpXhe+vfY895/YguSAZAKCQKfBo90cxt89cBHYIFLmF1FrV1Pw4OzuL3BL7VHPdKysrGYCIiMxVoa3Al5e/xHvn30NacRoAoIO8A6bdNQ0ze82Et9Jb5BZSW8FuL3FY67ozABGRXSjWFOOzS5/hg/MfILc8FwDQ0akjZvWehak9p8LV0VXkFhJRS2IAIqJ2La88Dx8lfoRPLn6CIk0RACDAJQBz+8zFI90fgdJBKXILidqG69evIywsDPHx8RgwYIDYzWk2BiAiapcySzLx/vn3sf/SfpRrywEAYe5hWNB3ASZ0mQC5VC5yC4nEkZqaivXr1+PQoUPIyclBQEAAJk+ejHXr1jVa1B0cHIyMjAx4e7ePbmIGICJqV64XXseec3vwzdVvUKWrAgD09uqNp8KfwgOdH+DkhWTXrl69ioiICPTo0QOffPIJwsLCcP78efz973/H999/j2PHjqFjx4719tNoNHB0dIS/v78IrbYNBiAiahcScxOxK2EXjtw4AgECAGCo/1BEhkciIiCCBatkM4IgoKxSK8pnK+Uyi363Fy5cCEdHR/zwww+GIeWdO3fGwIED0bVrV6xZswY7duxAaGgoFixYgMuXL+PLL7/Eo48+ipdeeqleF9jXX3+N5cuXIzU1FREREZg7dy7mzp2L/Px8eHh42OCMrYcBiIjaLEEQcCrrFHad24Xf0343LL+v031YEL4AA3wHiNc4shtllVr0XndYlM++sHEsnB3N+yrPy8vD4cOHsWnTJkP4qeHv74+ZM2di3759eOeddwAAr7/+OtatW4f169ebPN61a9fw2GOPYenSpYiMjER8fDxWrFjRvBNqQQxARNTmCIKA/6X9D7sSdiE+Ox4AIJVIMS50HBaEL0APzx4it5Co9bl8+TIEQUCvXr1Mru/Vqxfy8/Nx69YtAMADDzyA5cuXG9Zfv37daPv/9//+H3r27IktW7YAAHr27Ilz585h06ZNtjkBK2MAIqI2Q6vT4ocbP2B3wm4k5ScBAORSOSZ3m4x5feYh2C1Y5BaSPVLKZbiwcaxon20pQRDM2m7IkCGNrk9KSsLQoUONlg0bNszi9oiFAYiIWj2NVoOvr3yNPef2ILUoFQDg7OCMqT2nYlbvWfBx9hG5hWTPJBKJ2d1QYurWrRskEgkSExPxyCOP1FufmJgIT09P+Pjo/z25uLi0dBNbVOv/X4yI7FZpZSk+v/Q5Pjj/AbLL9A9A9FB4YGavmZh+13S4K9xFbiFR2+Hl5YXRo0fjnXfewbJly4zqgDIzM/HRRx9h9uzZZhdV9+zZE999953RspMnT1q1zbbE8aBE1OoUVhRix5kdGPPFGLz+5+vILsuGr7Mv/jH0Hzg85TCe6f8Mww9RE2zbtg0VFRUYO3Ysjh49itTUVBw6dAijR49GUFCQRfU7f/vb33Dx4kWsXLkSly5dwmeffYa9e/cCaBuPCWEAIqJWI7s0G6+ffB2j94/GO2ffQWFFITq7dsaGuzfg+0e/x6zes+As5wMoiZqqe/fu+PPPP9GlSxc88cQT6Nq1K55++mncf//9iIuLMzkHUEPCwsKwf/9+HDhwAP369cOOHTuwZs0aAIBCobDVKVgNu8CISHSp6lTsOb8HXyV/hUqd/knbPT17IjI8EqNDRkMmbfoTn4nIWEhIiOFOTUPqjvgCgNDQ0HoF1JMmTcKkSZMM7zdt2oROnTrBycnJGk21KQYgIhJNUl4Sdp/bjcPXD0Mn6AAAg3wHITI8EiODRraJ2+hE9uydd97B0KFD4eXlhd9//x1btmzBokWLxG6WWUTvAtu+fTtCQ0Ph5OQElUqFEydONLp9QUEBFi5ciICAACgUCvTo0aNeEZalxySilnUm+wwWxS7CY988hu+vfQ+doMPIoJHYO24v3h//Pu7pdA/DD1EbcPnyZTz88MPo3bs3Xn75ZSxfvhwvvfSS2M0yi6h3gPbt24eoqCjs3LkTKpUKMTExGDt2LJKSkuDr61tve41Gg9GjR8PX1xf79+9HUFAQbty4YTTdtqXHJKKWIQgC/kj/A7sSduHPrD8BABJIMCZ0DBb0XYBeXqYnZyOi1uvNN9/Em2++KXYzmkQimDsjkg2oVCoMHToU27ZtAwDodDoEBwdj8eLFWLVqVb3td+7ciS1btuDixYuQy00/ydnSY5qiVqvh7u6OwsJCuLm5NfHsiAjQT14YmxKLXQm7kJiXCABwkDpgUtdJmNdnHkLdQ8VtIJGFysvLce3aNYSFhbWJWpf2prHrb8n3t2h3gDQaDU6dOoXVq1cblkmlUowaNQpxcXEm9/n6668RERGBhQsX4quvvoKPjw9mzJiBlStXQiaTNemYAFBRUYGKigrDe7VabYUzJLJvldpKfHv1W+w5twfX1dcBAEoHJaZ0n4I5febA36X9PFWaiNoe0QJQTk4OtFot/Pz8jJb7+fnh4sWLJve5evUqfvrpJ8ycORPfffcdkpOT8dxzz6GyshLr169v0jEBIDo6Ghs2bGj+SRERyqrKcODyAew9vxeZJZkAAFdHV8y4awZm9poJTydPkVtIRNTGRoHpdDr4+vri3XffhUwmw+DBg5GWloYtW7Y0+LRac6xevRpRUVGG92q1GsHBfKYQkSXUGjU+vfgpPrzwIfIr8gEA3kpvzO49G0/0fAIu8vY9rT4RtS2iBSBvb2/IZDJkZWUZLc/KyoK/v+lb4wEBAZDL5ZDJbs8J0qtXL2RmZkKj0TTpmIB+wqa2MGkTUWuUU5aD/1z4D/Yl7UNJZQkAIKhDEOb3nY+Huz0MhYz/toio9RFtGLyjoyMGDx6M2NhYwzKdTofY2FhERESY3GfEiBFITk6GTqczLLt06RICAgLg6OjYpGMSUdOkFafhlWOvYNwX47Dn3B6UVJagm0c3RN8TjW8f+RZP9HyC4YeIWi1Ru8CioqIwZ84cDBkyBMOGDUNMTAxKSkowb948AMDs2bMRFBSE6OhoAMCzzz6Lbdu2YenSpVi8eDEuX76MzZs3Y8mSJWYfk4ia50rBFexO2I3vrn0HraAFAPTz7ofI8EjcG3wvpBLRpxcjIrojUQPQ1KlTcevWLaxbtw6ZmZkYMGAADh06ZChiTklJgVR6+49pcHAwDh8+jGXLlqFfv34ICgrC0qVLsXLlSrOPSURNk3ArAbsSduGn1J8MyyICIhAZHomh/kM5cSFRG5GZmYlNmzbh4MGDSEtLg6+vLwYMGIDnn38eDz74oEXHKi8vxzPPPINTp04hMTER//d//4cvv/zSNg23MlHnAWqtOA8QkZ4gCDieeRy7EnbheMZxw/JRnUchMjwSfbz7iNg6InG05XmArl+/jhEjRsDDwwMbN25EeHg4KisrcfjwYbz77ruNjpg2paSkBCtWrMCgQYPwxRdfwMnJyeYBqM3PA0RErZdO0OHn1J+xO2E3EnISAAAOEgdM6DIBC/ouQBePLiK3kKgVEQSgslScz5Y7AxbcfX3uuecgkUhw4sQJuLjcHpnZp08fzJ8/3+KPd3FxwY4dOwAAv//+OwoKCiw+hlgYgIjIoFJXiUPXDmF3wm5cKbwCAFDIFHi0+6OY22cuAjsEitxColaoshTYLNK/jRfSAUfzppjIy8vDoUOHsGnTJqPwU6PmsVLjx4/H//73vwaPExISgvPnzzepua0JAxARobyqHF8mf4m95/cirTgNANBB3gHT7pqGmb1mwlvpLXILiai5kpOTIQgC7rrrrka327VrF8rKyhpc39CjqNoaBiAiO1asKca+pH34z4X/ILc8FwDQ0akjZvWehak9p8LV0VXkFhK1AXJn/Z0YsT7bTOaW/AYFBTW1NW0KAxCRHcorz8OHFz7Epxc/RVFlEQAgwCUAc/vMxSPdH4HSQSlyC4naEInE7G4oMXXv3h0SieSOhc7sAiOidiezJBN7z+/FF5e+QLm2HAAQ5h6GBX0XYEKXCZBL28etbSKqr2PHjhg7diy2b9+OJUuW1KsDKigogIeHB7vAiKj9uFZ4DXvO7cG3V75FlVAFAOjt1RtPhT+FBzo/wMkLiezE9u3bMWLECAwbNgwbN25Ev379UFVVhSNHjmDHjh1ITEy0uAvswoUL0Gg0yMvLQ1FREc6cOQMAGDBggPVPwIoYgIjasQu5F7ArYRd+vPEjBOj7/4f5D8OC8AWICIjg5IVEdqZLly44ffo0Nm3ahOXLlyMjIwM+Pj4YPHiwYTi7pSZMmIAbN24Y3g8cOBCA+TVHYmEAImpnBEHAqaxT2JWwC7+n/25Yfl/wfYgMj0R/n/4ito6IxBYQEIBt27Zh27ZtVjne9evXrXKclsYARNROCIKAozePYlfCLpy5dQYAIJVIMT5sPOb3nY8enj3EbSARUSvCAETUBgmCgMKKQmSXZeNW6S3cLLqJzy59hkv5lwAAcqkcj3R7BHP7zkWwa7DIrSUian0YgIhaEUEQUFxZjFultwzhJrs0G7fKqv9besvwulJXWW9/ZwdnTO05FbN6z4KPs48IZ0BE1DYwABG1kLKqMpOBpibo1Cwrq2p4+GldngpP+Dj7wEfpg0F+gzC151S4K9xteBZERO0DAxBRM2m0Gtwqu9V4uCm9ZZhw0Byujq7wVfrCx9kHvs6+8FH6GL32dfaFt9IbjjJHG54ZEVH7xQBE1IAqXRVyy3LrBZq64aagosDsYyodlMaBpk7I8XXWv+dMzEREtsUARHZHJ+iQV55n1O1kquYmtyzXMHfOnThKHU0GmdqvfZW+cJG7cO4dIqJWgAGI2g1BEKDWqOvdralbPJxblmuYDflOZBIZvJXeRndt/Jz96t29cXN0Y7AhImpDGICo1RMEASWVJfXu0JiqudHoNGYdUwIJvJRe9e7Q1K256ejUkY+JICJqhxiASFQ2HRlVO9TUCTdeSi84SPnrT0Rkr/gNQDah0WqQU5bT4Bw2NSGnSGPByCi5a/1gY6LmhiOjiIhMmzt3LgoKCvDll1/WW1dWVoZ//vOf+OSTT3Djxg24urri/vvvx0svvYQ+ffoAAEJDQ42e+1XXnDlzsHfvXgDAt99+iy1btuD06dPQarXo06cPFi5ciLlz5xrt89///hevvvoqEhMTodPp0LlzZ4wePRoxMTFWOmvTGIDIIg2NjKo75Du/It/sY5ozMspb6Q1nubMNz4yIyH5VVFRg1KhRSElJwRtvvAGVSoWsrCxER0dDpVLhxx9/xPDhw3Hy5ElotVoAwB9//IEpU6YgKSkJbm5uAAClUj+C9e2338bzzz+PlStXYseOHXB0dMRXX32FZ555BufOncPrr78OAIiNjcXUqVOxadMmTJo0CRKJBBcuXMCRI0dsfs4MQARAPzIqvzy/wTlsskqzLB4ZJZfKG5zDhiOjiKi9EATBom56a1I6KK3y9zMmJgZxcXGIj49H//76ByaHhITgiy++gEqlwoIFC3Du3Dn4+NyeYb5jx44AAF9fX3h4eBiWp6amYvny5Xj++eexefNmw/Lly5fD0dERS5YsweOPPw6VSoVvvvkGI0aMwN///nfDdj169MDkyZObfU53wgDUzpkaGVWvkLgsGzmlOc0aGVW3K8pX6Qt3hTuDDRG1e2VVZVB9rBLls4/POG6Vu+Mff/wxRo8ebQg/NaRSKZYtW4aZM2fi7NmzGDBgwB2PtX//flRWVmLFihX11v3tb3/DCy+8gE8++QQqlQr+/v74+OOPce7cOfTt27fZ52EJBqA2rKSyxGSwsfXIKE+FJ2RSmY3PjoiIWsqlS5dw//33m1zXq1cvwzbmBKBLly7B3d0dAQEB9dY5OjqiS5cuuHRJ/+DmxYsX43//+x/Cw8MREhKC4cOHY8yYMZg5cyYUCkXTT8gMDECtUFlVGXJKc0w/DLPW8O/SqlKzj+mh8DAKNKZCjpfSC3Kp3IZnRkTU/igdlDg+47hon20tgmBeeYM1ubi44ODBg7hy5Qp+/vlnHDt2DMuXL8e//vUvxMXFwdnZdrWfDEAtqFJbqR8Z1cAEfbYaGeWt9IZCZtskTURkryQSSZsfpNGjRw8kJiaaXFezvEePHmYfq7CwEOnp6QgMDDRap9FocOXKlXp3m7p27YquXbsiMjISa9asQY8ePbBv3z7MmzevCWdjHgagFrTj7A78O+HfZm2rdFAajYoy3K3hyCgiIrKyadOmYc2aNTh79qxRHZBOp8Obb76J3r1716sPasiUKVOwcuVKvPHGG3jjjTeM1u3cuRMlJSWYPn16g/uHhobC2dkZJSUlTTsZMzEAtSAfZ59GR0bVvovTQd6BBcRERGR1hYWFOHPmjNGyJ598El999RUmTpxoNAx+8+bNSExMxI8//mj2d1Lnzp3x2muvYfny5XBycsKsWbMgl8vx1Vdf4YUXXsDy5cuhUumLxl966SWUlpZiwoQJCAkJQUFBAd566y1UVlZi9OjR1j51IwxALeixHo9hWs9pDDZERCSaX375BQMHDjRatmDBAvz000/YvHkzXnjhBaOJEI8dO2bxCK3nn38eXbp0weuvv45//etfhokQd+zYYdStde+992L79u2YPXs2srKy4OnpiYEDB+KHH35Az549rXK+DZEIYlQ9tXJqtRru7u4oLCw0TO5EREQEAOXl5bh27RrCwsLg5OQkdnPsTmPX35Lvbz7lkYiIiOwOAxARERHZHQYgIiIisjsMQERERGR3GICIiIiagGOIxGGt684AREREZAG5XP/IoNJS8x9HRNZTc91r/ndoKs4DREREZAGZTAYPDw9kZ2cDAJydnTm/WwsQBAGlpaXIzs6Gh4cHZLLmPZSbAYiIiMhC/v7+AGAIQdRyPDw8DNe/ORiAiIiILCSRSBAQEABfX19UVlaK3Ry7IZfLm33npwYDEBERURPJZDKrfSFTy2IRNBEREdkdBiAiIiKyOwxAREREZHdYA2RCzSRLarVa5JYQERGRuWq+t82ZLJEByISioiIAQHBwsMgtISIiIksVFRXB3d290W0kAufyrken0yE9PR2urq5Wn9xKrVYjODgYqampcHNzs+qx2xteK/PxWpmP18p8vFbm47Uyny2vlSAIKCoqQmBgIKTSxqt8eAfIBKlUik6dOtn0M9zc3PiPxEy8VubjtTIfr5X5eK3Mx2tlPltdqzvd+anBImgiIiKyOwxAREREZHcYgFqYQqHA+vXroVAoxG5Kq8drZT5eK/PxWpmP18p8vFbmay3XikXQREREZHd4B4iIiIjsDgMQERER2R0GICIiIrI7DEBERERkdxiAbCQtLQ1PPvkkvLy8oFQqER4ejj///NOwXhAErFu3DgEBAVAqlRg1ahQuX74sYovFERoaColEUu9n4cKFAIDy8nIsXLgQXl5e6NChA6ZMmYKsrCyRWy0OrVaLtWvXIiwsDEqlEl27dsXLL79s9Mwb/l7dVlRUhOeffx4hISFQKpW4++67cfLkScN6e75WR48excSJExEYGAiJRIIvv/zSaL051yYvLw8zZ86Em5sbPDw8sGDBAhQXF7fgWbSMO12rAwcOYMyYMfDy8oJEIsGZM2fqHcNe/o41dq0qKyuxcuVKhIeHw8XFBYGBgZg9ezbS09ONjtGSv1cMQDaQn5+PESNGQC6X4/vvv8eFCxfwxhtvwNPT07DNa6+9hrfeegs7d+7E8ePH4eLigrFjx6K8vFzElre8kydPIiMjw/Bz5MgRAMDjjz8OAFi2bBm++eYbfP755/j111+Rnp6ORx99VMwmi+bVV1/Fjh07sG3bNiQmJuLVV1/Fa6+9hrffftuwDX+vbouMjMSRI0fwn//8BwkJCRgzZgxGjRqFtLQ0APZ9rUpKStC/f39s377d5Hpzrs3MmTNx/vx5HDlyBN9++y2OHj2Kp59+uqVOocXc6VqVlJRg5MiRePXVVxs8hr38HWvsWpWWluL06dNYu3YtTp8+jQMHDiApKQmTJk0y2q5Ff68EsrqVK1cKI0eObHC9TqcT/P39hS1bthiWFRQUCAqFQvjkk09aoomt1tKlS4WuXbsKOp1OKCgoEORyufD5558b1icmJgoAhLi4OBFbKY6HHnpImD9/vtGyRx99VJg5c6YgCPy9qq20tFSQyWTCt99+a7R80KBBwpo1a3itagEg/Pe//zW8N+faXLhwQQAgnDx50rDN999/L0gkEiEtLa3F2t7S6l6r2q5duyYAEOLj442W2+vfscauVY0TJ04IAIQbN24IgtDyv1e8A2QDX3/9NYYMGYLHH38cvr6+GDhwIP79738b1l+7dg2ZmZkYNWqUYZm7uztUKhXi4uLEaHKroNFo8OGHH2L+/PmQSCQ4deoUKisrja7TXXfdhc6dO9vldbr77rsRGxuLS5cuAQDOnj2L3377DePHjwfA36vaqqqqoNVq4eTkZLRcqVTit99+47VqhDnXJi4uDh4eHhgyZIhhm1GjRkEqleL48eMt3ubWjH/HGlZYWAiJRAIPDw8ALf97xQBkA1evXsWOHTvQvXt3HD58GM8++yyWLFmC999/HwCQmZkJAPDz8zPaz8/Pz7DOHn355ZcoKCjA3LlzAeivk6Ojo+EfRw17vU6rVq3CtGnTcNddd0Eul2PgwIF4/vnnMXPmTAD8varN1dUVERERePnll5Geng6tVosPP/wQcXFxyMjI4LVqhDnXJjMzE76+vkbrHRwc0LFjR7u/fnXx75hp5eXlWLlyJaZPn254IGpL/17xafA2oNPpMGTIEGzevBkAMHDgQJw7dw47d+7EnDlzRG5d67V7926MHz8egYGBYjelVfrss8/w0Ucf4eOPP0afPn1w5swZPP/88wgMDOTvlQn/+c9/MH/+fAQFBUEmk2HQoEGYPn06Tp06JXbTiOxaZWUlnnjiCQiCgB07dojWDt4BsoGAgAD07t3baFmvXr2QkpICAPD39weAeqMAsrKyDOvszY0bN/Djjz8iMjLSsMzf3x8ajQYFBQVG29rrdfr73/9uuAsUHh6OWbNmYdmyZYiOjgbA36u6unbtil9//RXFxcVITU3FiRMnUFlZiS5duvBaNcKca+Pv74/s7Gyj9VVVVcjLy7P761cX/44Zqwk/N27cwJEjRwx3f4CW/71iALKBESNGICkpyWjZpUuXEBISAgAICwuDv78/YmNjDevVajWOHz+OiIiIFm1ra/Hee+/B19cXDz30kGHZ4MGDIZfLja5TUlISUlJS7PI6lZaWQio1/icrk8mg0+kA8PeqIS4uLggICEB+fj4OHz6Mhx9+mNeqEeZcm4iICBQUFBjdTfvpp5+g0+mgUqlavM2tGf+O3VYTfi5fvowff/wRXl5eRutb/PfK6mXVJJw4cUJwcHAQNm3aJFy+fFn46KOPBGdnZ+HDDz80bPPPf/5T8PDwEL766ivhr7/+Eh5++GEhLCxMKCsrE7Hl4tBqtULnzp2FlStX1lv3zDPPCJ07dxZ++ukn4c8//xQiIiKEiIgIEVopvjlz5ghBQUHCt99+K1y7dk04cOCA4O3tLfzjH/8wbMPfq9sOHTokfP/998LVq1eFH374Qejfv7+gUqkEjUYjCIJ9X6uioiIhPj5eiI+PFwAIW7duFeLj4w2jccy5NuPGjRMGDhwoHD9+XPjtt9+E7t27C9OnTxfrlGzmTtcqNzdXiI+PFw4ePCgAED799FMhPj5eyMjIMBzDXv6ONXatNBqNMGnSJKFTp07CmTNnhIyMDMNPRUWF4Rgt+XvFAGQj33zzjdC3b19BoVAId911l/Duu+8ardfpdMLatWsFPz8/QaFQCA8++KCQlJQkUmvFdfjwYQGAyfMvKysTnnvuOcHT01NwdnYWHnnkEaM/LPZErVYLS5cuFTp37iw4OTkJXbp0EdasWWP0x4O/V7ft27dP6NKli+Do6Cj4+/sLCxcuFAoKCgzr7fla/fzzzwKAej9z5swRBMG8a5ObmytMnz5d6NChg+Dm5ibMmzdPKCoqEuFsbOtO1+q9994zuX79+vWGY9jL37HGrlXNNAGmfn7++WfDMVry90oiCLWmkSUiIiKyA6wBIiIiIrvDAERERER2hwGIiIiI7A4DEBEREdkdBiAiIiKyOwxAREREZHcYgIiIiMjuMAARERGR3WEAIiIyg0QiwZdffil2M4jIShiAiKjVmzt3LiQSSb2fcePGid00ImqjHMRuABGROcaNG4f33nvPaJlCoRCpNUTU1vEOEBG1CQqFAv7+/kY/np6eAPTdUzt27MD48eOhVCrRpUsX7N+/32j/hIQEPPDAA1AqlfDy8sLTTz+N4uJio2327NmDPn36QKFQICAgAIsWLTJan5OTg0ceeQTOzs7o3r07vv76a9ueNBHZDAMQEbULa9euxZQpU3D27FnMnDkT06ZNQ2JiIgCgpKQEY8eOhaenJ06ePInPP/8cP/74o1HA2bFjBxYuXIinn34aCQkJ+Prrr9GtWzejz9iwYQOeeOIJ/PXXX5gwYQJmzpyJvLy8Fj1PIrISmzxjnojIiubMmSPIZDLBxcXF6GfTpk2CIAgCAOGZZ54x2kelUgnPPvusIAiC8O677wqenp5CcXGxYf3BgwcFqVQqZGZmCoIgCIGBgcKaNWsabAMA4cUXXzS8Ly4uFgAI33//vdXOk4haDmuAiKhNuP/++7Fjxw6jZR07djS8joiIMFoXERGBM2fOAAASExPRv39/uLi4GNaPGDECOp0OSUlJkEgkSE9Px4MPPthoG/r162d47eLiAjc3N2RnZzf1lIhIRAxARNQmuLi41OuSshalUmnWdnK53Oi9RCKBTqezRZOIyMZYA0RE7cKxY8fqve/VqxcAoFevXjh79ixKSkoM63///XdIpVL07NkTrq6uCA0NRWxsbIu2mYjEwztARNQmVFRUIDMz02iZg4MDvL29AQCff/45hgwZgpEjR+Kjjz7CiRMnsHv3bgDAzJkzsX79esyZMwcvvfQSbt26hcWLF2PWrFnw8/MDALz00kt45pln4Ovri/Hjx6OoqAi///47Fi9e3LInSkQtggGIiNqEQ4cOISAgwGhZz549cfHiRQD6EVqffvopnnvuOQQEBOCTTz5B7969AQDOzs44fPgwli5diqFDh8LZ2RlTpkzB1q1bDceaM2cOysvL8eabb2LFihXw9vbGY4891nInSEQtSiIIgiB2I4iImkMikeC///0vJk+eLHZTiKiNYA0QERER2R0GICIiIrI7rAEiojaPPflEZCneASIiIiK7wwBEREREdocBiIiIiOwOAxARERHZHQYgIiIisjsMQERERGR3GICIiIjI7jAAERERkd35/yGew7yJlumtAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.clf()\n",
    "plt.plot(orig_results['epoch'], orig_results['trans'], label='Orig')\n",
    "plt.plot(clip_results['epoch'], clip_results['trans'], label='C=1')\n",
    "plt.plot(lotos_results['epoch'], lotos_results['trans'], label='LOTOS')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Transferability')\n",
    "plt.legend()\n",
    "plt.savefig('figs/transferability.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "plt.plot(orig_results['epoch'], orig_results['robust'], label='Orig')\n",
    "plt.plot(clip_results['epoch'], clip_results['robust'], label='C=1')\n",
    "plt.plot(lotos_results['epoch'], lotos_results['robust'], label='LOTOS')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Robust Accuracy') \n",
    "plt.legend()\n",
    "plt.savefig('figs/robustness.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "\n",
    "plt.plot(orig_results['epoch'], orig_results['acc'], label='Orig')\n",
    "plt.plot(clip_results['epoch'], clip_results['acc'], label='C=1')\n",
    "plt.plot(lotos_results['epoch'], lotos_results['acc'], label='LOTOS')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy') \n",
    "plt.legend()\n",
    "plt.savefig('figs/accuracy.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
